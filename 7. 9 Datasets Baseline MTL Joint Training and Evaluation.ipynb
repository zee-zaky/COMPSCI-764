{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71614c8c-099c-4c44-91f3-5cd0ea933243",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0. Imports, libraries and rusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebea513d-21f8-4f2a-b64e-e52e6acbed93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from project_imports import *\n",
    "import use_gpu\n",
    "# Clear any cached memory to start fresh for each trial\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b95e38-f23f-4972-a8cb-b4c1849cb726",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb17c692-f274-4f42-8985-1b42f4f1cfd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Arguments and global vriables\n",
    "dataset_name=\"MCQA-Combined-9\"\n",
    "global_run_name=\"Optuna-1\"\n",
    "#pretrained_model_name = \"microsoft/deberta-v3-base\"\n",
    "pretrained_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "normalized_model_name = pretrained_model_name.replace(\"/\", \"-\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "assert isinstance( tokenizer, PreTrainedTokenizerFast )\n",
    "data_collator = DefaultDataCollator()\n",
    "max_length = 512 # The maximum length of a feature (question and context)\n",
    "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\n",
    "pad_on_right = right_padding = tokenizer.padding_side == 'right'\n",
    "global_counter = 0\n",
    "traing_answer_mismatches = []\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff5d0e7-f055-4058-986f-f82edc6fce8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Prepare the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38eef2e-4a62-434a-a3df-31a558fc1f42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Context', 'Question', 'Options', 'Label_Text', 'Label', 'Type', 'Source Dataset'],\n",
       "        num_rows: 1072514\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Context', 'Question', 'Options', 'Label_Text', 'Label', 'Type', 'Source Dataset'],\n",
       "        num_rows: 118521\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Context', 'Question', 'Options', 'Label_Text', 'Label', 'Type', 'Source Dataset'],\n",
       "        num_rows: 200566\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the combined dataset\n",
    "combined_dataset = load_from_disk('cleaned_dataset')\n",
    "\n",
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49b14e4b-8c9a-4cf4-817e-e8b7099bf1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize lists to hold datasets\n",
    "train_datasets = []\n",
    "val_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "# List of datasets to combine\n",
    "datasets_to_combine = ['AR-LSAT', 'ReClor', 'LogiQA 2.0', 'RTE', 'FOLIO', 'PrOntoQA', 'MRPC', 'Adversarial NLI', 'ConTRoL' ]\n",
    "\n",
    "# Loop through each dataset and filter\n",
    "for ds_name in datasets_to_combine:\n",
    "    train_datasets.append(combined_dataset['train'].filter(lambda x: x['Source Dataset'] == ds_name))\n",
    "    val_datasets.append(combined_dataset['validation'].filter(lambda x: x['Source Dataset'] == ds_name))\n",
    "    test_datasets.append(combined_dataset['test'].filter(lambda x: x['Source Dataset'] == ds_name))\n",
    "\n",
    "# Concatenate datasets\n",
    "combined_train = concatenate_datasets(train_datasets)\n",
    "combined_val = concatenate_datasets(val_datasets)\n",
    "combined_test = concatenate_datasets(test_datasets)\n",
    "\n",
    "# Concatenate validation data into the training data and use the Test dataset for validation \n",
    "combined_train = concatenate_datasets([combined_train, combined_val])\n",
    "combined_val = combined_test\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "# To ensure that each training batch has a chance to contain a mix of examples from all sources. \n",
    "# This helps in reducing variance and improving the generalization of the model.\n",
    "combined_train = combined_train.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944988bb-97a9-4daf-80a6-743daea9b62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mcqa_preprocess_function(examples):\n",
    "    # Determine the maximum number of choices\n",
    "    max_num_choices = 5  # Since AR-LSAT has 5 options, we'll pad others to 5\n",
    "    contexts = examples['Context']\n",
    "    questions = examples['Question']\n",
    "    options_list = examples['Options']\n",
    "    labels = examples['Label']\n",
    "    \n",
    "    first_sentences = []\n",
    "    second_sentences = []\n",
    "    labels_adjusted = []\n",
    "    \n",
    "    for context, question, options, label in zip(contexts, questions, options_list, labels):\n",
    "        num_choices = len(options)\n",
    "        # Pad options to have max_num_choices\n",
    "        if num_choices < max_num_choices:\n",
    "            options += [''] * (max_num_choices - num_choices)\n",
    "        first_sentences.append([context] * max_num_choices)\n",
    "        second_sentences.append([f\"{question} {option}\" for option in options])\n",
    "        labels_adjusted.append(label)\n",
    "    \n",
    "    # Flatten the lists\n",
    "    first_sentences = [item for sublist in first_sentences for item in sublist]\n",
    "    second_sentences = [item for sublist in second_sentences for item in sublist]\n",
    "    \n",
    "    # Tokenize the inputs\n",
    "    tokenized_examples = tokenizer(\n",
    "        first_sentences,\n",
    "        second_sentences,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "    )\n",
    "    \n",
    "    # Un-flatten to shape (num_examples, max_num_choices, seq_length)\n",
    "    tokenized_inputs = {\n",
    "        k: [v[i:i + max_num_choices] for i in range(0, len(v), max_num_choices)]\n",
    "        for k, v in tokenized_examples.items()\n",
    "    }\n",
    "    \n",
    "    # Labels\n",
    "    tokenized_inputs[\"labels\"] = labels_adjusted\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29057a47-41c8-4073-ad1c-6e08a04ed14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da5efd809e8428eabcaa4d6c3b31f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef49640130c8466cb3aa3bff82744646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5569 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the preprocessing function to the combined datasets\n",
    "encoded_train = combined_train.map(mcqa_preprocess_function, batched=True)\n",
    "encoded_val = combined_val.map(mcqa_preprocess_function, batched=True)\n",
    "encoded_test = combined_test.map(mcqa_preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27035bf4-f8bd-4e10-8b8e-80e6c33cb9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 36630\n",
      "Number of validation examples: 5569\n",
      "Number of test examples: 5569\n"
     ]
    }
   ],
   "source": [
    "# Set the format of the datasets to PyTorch tensors\n",
    "encoded_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "encoded_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "encoded_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "\n",
    "def get_train_encoded():\n",
    "    return encoded_train\n",
    "\n",
    "def get_val_encoded():\n",
    "    return encoded_val\n",
    "\n",
    "def get_test_encoded():\n",
    "    return encoded_test\n",
    "\n",
    "\n",
    "print(\"Number of training examples:\", len(encoded_train))\n",
    "print(\"Number of validation examples:\", len(encoded_val))\n",
    "print(\"Number of test examples:\", len(encoded_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba1af4-7b57-4c74-bcd9-48edefba6747",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Reusable Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb8384ce-d55e-4aa1-911b-7d8ac3ab07df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the accuracy metric\n",
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "# Define the compute_metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)['accuracy']\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    return {'eval_accuracy': acc, 'eval_f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62ae25b-b560-4182-a68d-e60ab612bc4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_training_args(run_name=\"Default-Run\", num_train_epochs=3, learning_rate=4.92e-05, batch_size=3):\n",
    "    \"\"\"\n",
    "    Generates training arguments for training a machine learning model.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_name (str): The name of the dataset.\n",
    "    - run_name (str): The name of the run, useful for logging and saving models.\n",
    "    - model_name (str): The name of the model, typically including its configuration.\n",
    "    - num_train_epochs (int): The number of epochs to train for.\n",
    "    - learning_rate (float): The learning rate for training.\n",
    "    - batch_size (int): The batch size used for training.\n",
    "\n",
    "    Returns:\n",
    "    - TrainingArguments: A configured TrainingArguments instance.\n",
    "    \"\"\"    \n",
    "    output_dir = f\"./{dataset_name}/{run_name}/{normalized_model_name}\"\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        report_to=\"none\",  # Disable all integrations\n",
    "        overwrite_output_dir=True,\n",
    "        metric_for_best_model='eval_accuracy',\n",
    "        greater_is_better=True,\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=3,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=4,\n",
    "        warmup_steps=398,\n",
    "        weight_decay=0.194,\n",
    "        adam_beta1=0.837,\n",
    "        adam_beta2=0.997,\n",
    "        adam_epsilon=5.87e-07,\n",
    "        lr_scheduler_type='cosine',\n",
    "        fp16=True,  # Enable mixed-precision training\n",
    "    )\n",
    "    \n",
    "    return training_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db0f0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(model_name=pretrained_model_name, dropout_rate=0.1):\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "    #model.config.hidden_dropout_prob = dropout_rate\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77fbc498-f422-4980-9a8c-bbcf0852c992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_trainer(model_name=pretrained_model_name,run_name=\"Default-Run\", num_train_epochs=3, learning_rate=4.92e-05, batch_size=4):\n",
    "    trainer = Trainer(\n",
    "        model=model_init(model_name),\n",
    "        args=create_training_args(run_name=run_name, num_train_epochs=num_train_epochs, learning_rate=learning_rate, batch_size=batch_size),\n",
    "        train_dataset=get_train_encoded(),\n",
    "        eval_dataset=get_val_encoded(),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af7e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedEarlyStoppingCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A callback to stop training when either the performance falls below a certain threshold\n",
    "    or if there is no improvement over a set number of epochs.\n",
    "    \"\"\"\n",
    "    def __init__(self, metric_name, patience):\n",
    "        self.metric_name = metric_name\n",
    "        self.patience = patience        \n",
    "        self.best_score = None\n",
    "        self.no_improve_epochs = 0\n",
    "        self.config_file = \"early_stopping_config.json\"  # Config file for early stopping values\n",
    "\n",
    "    def read_early_stopping_config(self):\n",
    "        \"\"\"\n",
    "        Reads the early stopping configuration from the file system.\n",
    "        Returns the configuration as a dictionary.\n",
    "        \"\"\"\n",
    "        if os.path.exists(self.config_file):\n",
    "            with open(self.config_file, 'r') as file:\n",
    "                config = json.load(file)\n",
    "            return config\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Config file not found: {self.config_file}\")\n",
    "    def reset_manual_stop_flag(self):\n",
    "        \"\"\"\n",
    "        Resets the manual stop flag to False in the early stopping config file.\n",
    "        \"\"\"\n",
    "        config = self.read_early_stopping_config()\n",
    "        config['manual_stop'] = False\n",
    "        with open(self.config_file, 'w') as file:\n",
    "            json.dump(config, file, indent=4)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        metric_value = kwargs['metrics'].get(self.metric_name)\n",
    "\n",
    "        if self.best_score is None or metric_value > self.best_score:\n",
    "            self.best_score = metric_value\n",
    "            self.no_improve_epochs = 0\n",
    "        else:\n",
    "            self.no_improve_epochs += 1\n",
    "\n",
    "        # Check if no improvement has been seen over the allowed patience\n",
    "        if self.no_improve_epochs >= self.patience:\n",
    "            control.should_training_stop = True\n",
    "            print(f\"Stopping training: No improvement in {self.metric_name} for {self.patience} epochs\")\n",
    "\n",
    "\n",
    "        # Read the early stopping configuration\n",
    "        config = self.read_early_stopping_config()\n",
    "        min_accuracy = config.get(\"min_accuracy\", 0.35)                \n",
    "        num_epochs_min_acc = config.get(\"num_epochs_min_acc\", 2)  \n",
    "        max_variance = config.get(\"max_variance\", 0.2)  \n",
    "\n",
    "        # Check if performance is below the threshold\n",
    "        if metric_value < min_accuracy:\n",
    "            control.should_training_stop = True\n",
    "            print(f\"Stopping training: {self.metric_name} below manual min_acc of {min_accuracy}\")\n",
    "\n",
    "         # Manual stop from config\n",
    "        if config.get(\"manual_stop\", False):\n",
    "            control.should_training_stop = True\n",
    "            print(f\"Manual early stopping triggered!!\")\n",
    "            self.reset_manual_stop_flag()  # Reset the flag for future runs\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a456ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    # Clear any cached memory to start fresh for each trial\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    model_name = trial.suggest_categorical('model_name', [pretrained_model_name])     \n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-7, 1e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [3, 4])\n",
    "    #warmup_steps = trial.suggest_int('warmup_steps', 0, 1000)\n",
    "    warmup_ratio= trial.suggest_float('warmup_ratio', 0.0, 1.0)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.0, 0.25)\n",
    "    adam_beta1 = trial.suggest_float('adam_beta1', 0.8, 0.95)\n",
    "    adam_beta2 = trial.suggest_float('adam_beta2', 0.990, 0.999)\n",
    "    adam_epsilon = trial.suggest_float('adam_epsilon', 1e-8, 1e-6)\n",
    "    lr_scheduler_type = trial.suggest_categorical('lr_scheduler_type', ['linear', 'cosine', 'cosine_with_restarts']) #,'constant_with_warmup'   \n",
    "    \n",
    "\n",
    "    output_dir = f\"./{dataset_name}/{global_run_name}/trial_{trial.number}\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        report_to=\"none\",  # Disable all integrations\n",
    "        overwrite_output_dir=True,\n",
    "        metric_for_best_model='eval_accuracy',\n",
    "        greater_is_better=True,\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=3,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=30,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        weight_decay=weight_decay,\n",
    "        adam_beta1=adam_beta1,\n",
    "        adam_beta2=adam_beta2,\n",
    "        adam_epsilon=adam_epsilon,\n",
    "        lr_scheduler_type=lr_scheduler_type,\n",
    "        fp16=True,  # Enable mixed-precision training\n",
    "    ) \n",
    "    \n",
    "    # Print trial parameters\n",
    "    print(f\"Current Trial {trial.number} parameters: {trial.params}\")\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model_init(model_name, dropout_rate),\n",
    "        args=training_args,\n",
    "        train_dataset=get_train_encoded(),\n",
    "        eval_dataset=get_val_encoded(),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[AdvancedEarlyStoppingCallback(metric_name='eval_accuracy', patience=1)]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "        \n",
    "    torch.cuda.empty_cache()  # Clear cache after evaluation\n",
    "    gc.collect()  # Collect garbage\n",
    "\n",
    "    return eval_results['eval_accuracy']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9b86e-63c3-4ee8-bb91-bbb43e5a6481",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. DeBERTa Joint MTL Training on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362fbe0",
   "metadata": {},
   "source": [
    "## 4.1 Optuna Hyperparameters Tuning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03dcd721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-20 19:13:54,181] A new study created in memory with name: no-name-7683d3f0-e950-4b81-96ad-469024148d0e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Trial 0 parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.0052258285035737e-05, 'batch_size': 3, 'warmup_ratio': 0.04149176551014211, 'weight_decay': 0.006685281279171756, 'adam_beta1': 0.9429922176765829, 'adam_beta2': 0.9918592948813898, 'adam_epsilon': 8.867767549079712e-08, 'lr_scheduler_type': 'cosine_with_restarts'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d600c42fb11e400cbd871c2b5bd1afde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6092, 'grad_norm': 2.5615124702453613, 'learning_rate': 3.306881467542515e-07, 'epoch': 0.04}\n",
      "{'loss': 1.6037, 'grad_norm': 3.1979482173919678, 'learning_rate': 6.607149172149945e-07, 'epoch': 0.08}\n",
      "{'loss': 1.5095, 'grad_norm': 3.0810492038726807, 'learning_rate': 9.90080311382229e-07, 'epoch': 0.12}\n",
      "{'loss': 1.3245, 'grad_norm': 8.836233139038086, 'learning_rate': 1.320107081842972e-06, 'epoch': 0.16}\n",
      "{'loss': 1.2577, 'grad_norm': 21.913860321044922, 'learning_rate': 1.650133852303715e-06, 'epoch': 0.2}\n",
      "{'loss': 1.2258, 'grad_norm': 18.503393173217773, 'learning_rate': 1.9808219990579663e-06, 'epoch': 0.25}\n",
      "{'loss': 1.217, 'grad_norm': 52.439456939697266, 'learning_rate': 2.311510145812218e-06, 'epoch': 0.29}\n",
      "{'loss': 1.1845, 'grad_norm': 15.72999382019043, 'learning_rate': 2.6421982925664694e-06, 'epoch': 0.33}\n",
      "{'loss': 1.1741, 'grad_norm': 21.107629776000977, 'learning_rate': 2.9728864393207205e-06, 'epoch': 0.37}\n",
      "{'loss': 1.1737, 'grad_norm': 25.750137329101562, 'learning_rate': 3.3035745860749725e-06, 'epoch': 0.41}\n",
      "{'loss': 1.1756, 'grad_norm': 27.776046752929688, 'learning_rate': 3.6342627328292237e-06, 'epoch': 0.45}\n",
      "{'loss': 1.168, 'grad_norm': 20.82364845275879, 'learning_rate': 3.964950879583476e-06, 'epoch': 0.49}\n",
      "{'loss': 1.1573, 'grad_norm': 9.999363899230957, 'learning_rate': 4.294977650044218e-06, 'epoch': 0.53}\n",
      "{'loss': 1.1756, 'grad_norm': 16.67936897277832, 'learning_rate': 4.62566579679847e-06, 'epoch': 0.57}\n",
      "{'loss': 1.1667, 'grad_norm': 14.429287910461426, 'learning_rate': 4.956353943552721e-06, 'epoch': 0.61}\n",
      "{'loss': 1.1174, 'grad_norm': 17.062349319458008, 'learning_rate': 5.287042090306973e-06, 'epoch': 0.66}\n",
      "{'loss': 1.1004, 'grad_norm': 25.356056213378906, 'learning_rate': 5.617068860767715e-06, 'epoch': 0.7}\n",
      "{'loss': 1.1372, 'grad_norm': 25.34347152709961, 'learning_rate': 5.947757007521968e-06, 'epoch': 0.74}\n",
      "{'loss': 1.0848, 'grad_norm': 21.02800941467285, 'learning_rate': 6.278445154276219e-06, 'epoch': 0.78}\n",
      "{'loss': 1.0938, 'grad_norm': 25.686864852905273, 'learning_rate': 6.609133301030471e-06, 'epoch': 0.82}\n",
      "{'loss': 1.0866, 'grad_norm': 28.939334869384766, 'learning_rate': 6.939160071491213e-06, 'epoch': 0.86}\n",
      "{'loss': 1.0976, 'grad_norm': 26.22161102294922, 'learning_rate': 7.269848218245465e-06, 'epoch': 0.9}\n",
      "{'loss': 1.0627, 'grad_norm': 10.362929344177246, 'learning_rate': 7.600536364999717e-06, 'epoch': 0.94}\n",
      "{'loss': 1.0715, 'grad_norm': 22.329378128051758, 'learning_rate': 7.931224511753968e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a152e956d1c74cf28dcd7b6fc790af90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.5905907703357874, 'eval_f1': 0.5895781964634637, 'eval_loss': 0.9495132565498352, 'eval_runtime': 198.1486, 'eval_samples_per_second': 28.105, 'eval_steps_per_second': 9.372, 'epoch': 1.0}\n",
      "{'loss': 1.0238, 'grad_norm': 14.375360488891602, 'learning_rate': 8.261251282214711e-06, 'epoch': 1.02}\n",
      "{'loss': 1.0012, 'grad_norm': 12.798364639282227, 'learning_rate': 8.591939428968962e-06, 'epoch': 1.06}\n",
      "{'loss': 1.0249, 'grad_norm': 31.285005569458008, 'learning_rate': 8.922627575723213e-06, 'epoch': 1.11}\n",
      "{'loss': 0.9969, 'grad_norm': 57.48112487792969, 'learning_rate': 9.253315722477465e-06, 'epoch': 1.15}\n",
      "{'loss': 0.9879, 'grad_norm': 31.293371200561523, 'learning_rate': 9.583342492938208e-06, 'epoch': 1.19}\n",
      "{'loss': 0.998, 'grad_norm': 13.259774208068848, 'learning_rate': 9.913369263398951e-06, 'epoch': 1.23}\n",
      "{'loss': 1.0144, 'grad_norm': 25.082748413085938, 'learning_rate': 1.0052241363685589e-05, 'epoch': 1.27}\n",
      "{'loss': 1.0157, 'grad_norm': 20.405954360961914, 'learning_rate': 1.0052132713376063e-05, 'epoch': 1.31}\n",
      "{'loss': 0.9707, 'grad_norm': 21.83221435546875, 'learning_rate': 1.0051923463133962e-05, 'epoch': 1.35}\n",
      "{'loss': 0.9631, 'grad_norm': 26.62657928466797, 'learning_rate': 1.0051613617147617e-05, 'epoch': 1.39}\n",
      "{'loss': 0.9063, 'grad_norm': 22.49317169189453, 'learning_rate': 1.0051203181618871e-05, 'epoch': 1.43}\n",
      "{'loss': 0.9394, 'grad_norm': 12.28970718383789, 'learning_rate': 1.0050692164762958e-05, 'epoch': 1.47}\n",
      "{'loss': 0.9429, 'grad_norm': 34.30947494506836, 'learning_rate': 1.0050080576808332e-05, 'epoch': 1.52}\n",
      "{'loss': 0.9588, 'grad_norm': 6.407827854156494, 'learning_rate': 1.0049368429996472e-05, 'epoch': 1.56}\n",
      "{'loss': 0.9426, 'grad_norm': 31.15106773376465, 'learning_rate': 1.0048559189611246e-05, 'epoch': 1.6}\n",
      "{'loss': 0.8911, 'grad_norm': 13.941301345825195, 'learning_rate': 1.0047646371938436e-05, 'epoch': 1.64}\n",
      "{'loss': 0.9094, 'grad_norm': 25.357629776000977, 'learning_rate': 1.0046633044131167e-05, 'epoch': 1.68}\n",
      "{'loss': 0.9037, 'grad_norm': 14.646191596984863, 'learning_rate': 1.0045519226472096e-05, 'epoch': 1.72}\n",
      "{'loss': 0.9063, 'grad_norm': 14.784881591796875, 'learning_rate': 1.0044307470076513e-05, 'epoch': 1.76}\n",
      "{'loss': 0.8917, 'grad_norm': 44.358131408691406, 'learning_rate': 1.0042992942467856e-05, 'epoch': 1.8}\n",
      "{'loss': 0.8953, 'grad_norm': 35.452301025390625, 'learning_rate': 1.0041577997867268e-05, 'epoch': 1.84}\n",
      "{'loss': 0.8871, 'grad_norm': 27.701702117919922, 'learning_rate': 1.0040065795430738e-05, 'epoch': 1.88}\n",
      "{'loss': 0.9114, 'grad_norm': 24.428205490112305, 'learning_rate': 1.0038450304504862e-05, 'epoch': 1.92}\n",
      "{'loss': 0.8964, 'grad_norm': 15.006647109985352, 'learning_rate': 1.0036734487511998e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9ed4efb564466a98d4145663b54a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.6545160711079189, 'eval_f1': 0.6564821117151657, 'eval_loss': 0.9943047761917114, 'eval_runtime': 196.8073, 'eval_samples_per_second': 28.297, 'eval_steps_per_second': 9.436, 'epoch': 2.0}\n",
      "{'loss': 0.8089, 'grad_norm': 56.8016357421875, 'learning_rate': 1.0034918378795748e-05, 'epoch': 2.01}\n",
      "{'loss': 0.7715, 'grad_norm': 3.731069803237915, 'learning_rate': 1.0033002014707146e-05, 'epoch': 2.05}\n",
      "{'loss': 0.7498, 'grad_norm': 62.90008544921875, 'learning_rate': 1.0030985433603921e-05, 'epoch': 2.09}\n",
      "{'loss': 0.7483, 'grad_norm': 79.11527252197266, 'learning_rate': 1.002886867584974e-05, 'epoch': 2.13}\n",
      "{'loss': 0.77, 'grad_norm': 60.97574234008789, 'learning_rate': 1.0026651783813394e-05, 'epoch': 2.17}\n",
      "{'loss': 0.7508, 'grad_norm': 38.055423736572266, 'learning_rate': 1.0024339535691075e-05, 'epoch': 2.21}\n",
      "{'loss': 0.7204, 'grad_norm': 51.701045989990234, 'learning_rate': 1.0021922710252429e-05, 'epoch': 2.25}\n",
      "{'loss': 0.7489, 'grad_norm': 25.378610610961914, 'learning_rate': 1.0019411022964792e-05, 'epoch': 2.29}\n",
      "{'loss': 0.7461, 'grad_norm': 38.40248489379883, 'learning_rate': 1.0016794457235728e-05, 'epoch': 2.33}\n",
      "{'loss': 0.7457, 'grad_norm': 3.7452356815338135, 'learning_rate': 1.0014077998900722e-05, 'epoch': 2.38}\n",
      "{'loss': 0.7735, 'grad_norm': 7.346003532409668, 'learning_rate': 1.0011261702332105e-05, 'epoch': 2.42}\n",
      "{'loss': 0.7631, 'grad_norm': 14.183451652526855, 'learning_rate': 1.000834562390056e-05, 'epoch': 2.46}\n",
      "{'loss': 0.7353, 'grad_norm': 76.131591796875, 'learning_rate': 1.00053359530621e-05, 'epoch': 2.5}\n",
      "{'loss': 0.7499, 'grad_norm': 28.660669326782227, 'learning_rate': 1.0002220687269157e-05, 'epoch': 2.54}\n",
      "{'loss': 0.7184, 'grad_norm': 36.94556427001953, 'learning_rate': 9.999005820577243e-06, 'epoch': 2.58}\n",
      "{'loss': 0.766, 'grad_norm': 56.750953674316406, 'learning_rate': 9.995691417334775e-06, 'epoch': 2.62}\n",
      "{'loss': 0.7744, 'grad_norm': 25.27529525756836, 'learning_rate': 9.992277543882486e-06, 'epoch': 2.66}\n",
      "{'loss': 0.7809, 'grad_norm': 122.600830078125, 'learning_rate': 9.988764268552085e-06, 'epoch': 2.7}\n",
      "{'loss': 0.8083, 'grad_norm': 16.767929077148438, 'learning_rate': 9.985151661664906e-06, 'epoch': 2.74}\n",
      "{'loss': 0.7425, 'grad_norm': 31.124242782592773, 'learning_rate': 9.98143979553049e-06, 'epoch': 2.78}\n",
      "{'loss': 0.7118, 'grad_norm': 109.77629852294922, 'learning_rate': 9.97763646548352e-06, 'epoch': 2.83}\n",
      "{'loss': 0.7654, 'grad_norm': 80.2856216430664, 'learning_rate': 9.973726503868701e-06, 'epoch': 2.87}\n",
      "{'loss': 0.7863, 'grad_norm': 14.85925579071045, 'learning_rate': 9.969717511691343e-06, 'epoch': 2.91}\n",
      "{'loss': 0.7119, 'grad_norm': 157.66522216796875, 'learning_rate': 9.96560956919499e-06, 'epoch': 2.95}\n",
      "{'loss': 0.7094, 'grad_norm': 15.486642837524414, 'learning_rate': 9.961402758603761e-06, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45579520b2254c9c9ce4a716e84721dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7103609265577303, 'eval_f1': 0.7114795283985499, 'eval_loss': 1.1255320310592651, 'eval_runtime': 197.8897, 'eval_samples_per_second': 28.142, 'eval_steps_per_second': 9.384, 'epoch': 3.0}\n",
      "{'loss': 0.6192, 'grad_norm': 2.6608753204345703, 'learning_rate': 9.957114583162602e-06, 'epoch': 3.03}\n",
      "{'loss': 0.5797, 'grad_norm': 0.04230521619319916, 'learning_rate': 9.952710685584603e-06, 'epoch': 3.07}\n",
      "{'loss': 0.5854, 'grad_norm': 2.5934066772460938, 'learning_rate': 9.94820817809436e-06, 'epoch': 3.11}\n",
      "{'loss': 0.5593, 'grad_norm': 0.8435695767402649, 'learning_rate': 9.943607150813569e-06, 'epoch': 3.15}\n",
      "{'loss': 0.5553, 'grad_norm': 14.582571029663086, 'learning_rate': 9.938917192914488e-06, 'epoch': 3.19}\n",
      "{'loss': 0.6155, 'grad_norm': 104.50506591796875, 'learning_rate': 9.93411960087576e-06, 'epoch': 3.24}\n",
      "{'loss': 0.5743, 'grad_norm': 25.260292053222656, 'learning_rate': 9.929223771041889e-06, 'epoch': 3.28}\n",
      "{'loss': 0.5997, 'grad_norm': 19.206375122070312, 'learning_rate': 9.924229801407265e-06, 'epoch': 3.32}\n",
      "{'loss': 0.6216, 'grad_norm': 114.87332153320312, 'learning_rate': 9.919137791930631e-06, 'epoch': 3.36}\n",
      "{'loss': 0.6076, 'grad_norm': 23.391084671020508, 'learning_rate': 9.913947844533087e-06, 'epoch': 3.4}\n",
      "{'loss': 0.5927, 'grad_norm': 29.252695083618164, 'learning_rate': 9.90866006309605e-06, 'epoch': 3.44}\n",
      "{'loss': 0.6246, 'grad_norm': 9.284010887145996, 'learning_rate': 9.903274553459164e-06, 'epoch': 3.48}\n",
      "{'loss': 0.654, 'grad_norm': 48.71213150024414, 'learning_rate': 9.897802487030823e-06, 'epoch': 3.52}\n",
      "{'loss': 0.6437, 'grad_norm': 15.614262580871582, 'learning_rate': 9.892222041245985e-06, 'epoch': 3.56}\n",
      "{'loss': 0.5977, 'grad_norm': 0.00043512904085218906, 'learning_rate': 9.886544196282933e-06, 'epoch': 3.6}\n",
      "{'loss': 0.6123, 'grad_norm': 147.36474609375, 'learning_rate': 9.880780713064221e-06, 'epoch': 3.64}\n",
      "{'loss': 0.6381, 'grad_norm': 16.513076782226562, 'learning_rate': 9.874908606856566e-06, 'epoch': 3.69}\n",
      "{'loss': 0.6003, 'grad_norm': 5.843256950378418, 'learning_rate': 9.868939448014486e-06, 'epoch': 3.73}\n",
      "{'loss': 0.5886, 'grad_norm': 99.63845825195312, 'learning_rate': 9.862873356016004e-06, 'epoch': 3.77}\n",
      "{'loss': 0.5867, 'grad_norm': 6.58687162399292, 'learning_rate': 9.856710452279352e-06, 'epoch': 3.81}\n",
      "{'loss': 0.6303, 'grad_norm': 23.200685501098633, 'learning_rate': 9.850450860160526e-06, 'epoch': 3.85}\n",
      "{'loss': 0.6312, 'grad_norm': 95.72096252441406, 'learning_rate': 9.84410751354698e-06, 'epoch': 3.89}\n",
      "{'loss': 0.637, 'grad_norm': 2.430145263671875, 'learning_rate': 9.837655115214003e-06, 'epoch': 3.93}\n",
      "{'loss': 0.6295, 'grad_norm': 23.769386291503906, 'learning_rate': 9.831106409908379e-06, 'epoch': 3.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e3c5feee55413f8d8dc7bcb9ac74c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7259831208475489, 'eval_f1': 0.7267615114179508, 'eval_loss': 1.5731713771820068, 'eval_runtime': 198.9224, 'eval_samples_per_second': 27.996, 'eval_steps_per_second': 9.335, 'epoch': 4.0}\n",
      "{'loss': 0.5874, 'grad_norm': 94.56400299072266, 'learning_rate': 9.824461528708268e-06, 'epoch': 4.01}\n",
      "{'loss': 0.4292, 'grad_norm': 20.633499145507812, 'learning_rate': 9.81772060461688e-06, 'epoch': 4.05}\n",
      "{'loss': 0.4809, 'grad_norm': 0.49937719106674194, 'learning_rate': 9.810883772559806e-06, 'epoch': 4.1}\n",
      "{'loss': 0.488, 'grad_norm': 284.4397888183594, 'learning_rate': 9.803965130076343e-06, 'epoch': 4.14}\n",
      "{'loss': 0.483, 'grad_norm': 0.00022683857241645455, 'learning_rate': 9.79693708566563e-06, 'epoch': 4.18}\n",
      "{'loss': 0.4443, 'grad_norm': 5.656628131866455, 'learning_rate': 9.789813549289851e-06, 'epoch': 4.22}\n",
      "{'loss': 0.4912, 'grad_norm': 0.0008017046493478119, 'learning_rate': 9.782594663532924e-06, 'epoch': 4.26}\n",
      "{'loss': 0.5107, 'grad_norm': 8.377302169799805, 'learning_rate': 9.775280572887273e-06, 'epoch': 4.3}\n",
      "{'loss': 0.5313, 'grad_norm': 0.003063496667891741, 'learning_rate': 9.767871423750923e-06, 'epoch': 4.34}\n",
      "{'loss': 0.4839, 'grad_norm': 21.90515899658203, 'learning_rate': 9.760367364424591e-06, 'epoch': 4.38}\n",
      "{'loss': 0.5229, 'grad_norm': 0.0023824400268495083, 'learning_rate': 9.752783837217019e-06, 'epoch': 4.42}\n",
      "{'loss': 0.4782, 'grad_norm': 0.0040634735487401485, 'learning_rate': 9.745090599071423e-06, 'epoch': 4.46}\n",
      "{'loss': 0.5169, 'grad_norm': 38.422386169433594, 'learning_rate': 9.737302906714316e-06, 'epoch': 4.5}\n",
      "{'loss': 0.4837, 'grad_norm': 186.39822387695312, 'learning_rate': 9.729420916023283e-06, 'epoch': 4.55}\n",
      "{'loss': 0.5492, 'grad_norm': 80.64409637451172, 'learning_rate': 9.721460830872393e-06, 'epoch': 4.59}\n",
      "{'loss': 0.5628, 'grad_norm': 26.99793815612793, 'learning_rate': 9.713390906494249e-06, 'epoch': 4.63}\n",
      "{'loss': 0.5081, 'grad_norm': 147.4690399169922, 'learning_rate': 9.705227162402136e-06, 'epoch': 4.67}\n",
      "{'loss': 0.5112, 'grad_norm': 22.410547256469727, 'learning_rate': 9.696969762000659e-06, 'epoch': 4.71}\n",
      "{'loss': 0.5285, 'grad_norm': 36.7302360534668, 'learning_rate': 9.688618870569032e-06, 'epoch': 4.75}\n",
      "{'loss': 0.5237, 'grad_norm': 21.44107437133789, 'learning_rate': 9.680174655257774e-06, 'epoch': 4.79}\n",
      "{'loss': 0.5057, 'grad_norm': 0.0034776655957102776, 'learning_rate': 9.671654452680994e-06, 'epoch': 4.83}\n",
      "{'loss': 0.4824, 'grad_norm': 0.5099244117736816, 'learning_rate': 9.663024284326673e-06, 'epoch': 4.87}\n",
      "{'loss': 0.4871, 'grad_norm': 5.6857991218566895, 'learning_rate': 9.654301304391135e-06, 'epoch': 4.91}\n",
      "{'loss': 0.5184, 'grad_norm': 107.54457092285156, 'learning_rate': 9.645485687472584e-06, 'epoch': 4.95}\n",
      "{'loss': 0.5329, 'grad_norm': 0.014585309661924839, 'learning_rate': 9.636577610023432e-06, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4619905c56154588bf4a8cfaf83625d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7347818279762973, 'eval_f1': 0.7355978519172677, 'eval_loss': 2.2864129543304443, 'eval_runtime': 208.5937, 'eval_samples_per_second': 26.698, 'eval_steps_per_second': 8.902, 'epoch': 5.0}\n",
      "{'loss': 0.4066, 'grad_norm': 163.7062225341797, 'learning_rate': 9.62759534304436e-06, 'epoch': 5.04}\n",
      "{'loss': 0.3261, 'grad_norm': 0.001990213757380843, 'learning_rate': 9.618503065313543e-06, 'epoch': 5.08}\n",
      "{'loss': 0.3665, 'grad_norm': 354.0205993652344, 'learning_rate': 9.609318867133312e-06, 'epoch': 5.12}\n",
      "{'loss': 0.3841, 'grad_norm': 28.654394149780273, 'learning_rate': 9.600042932333566e-06, 'epoch': 5.16}\n",
      "{'loss': 0.418, 'grad_norm': 0.0005896627553738654, 'learning_rate': 9.59071309864501e-06, 'epoch': 5.2}\n",
      "{'loss': 0.4016, 'grad_norm': 0.0010921013308688998, 'learning_rate': 9.581254614514861e-06, 'epoch': 5.24}\n",
      "{'loss': 0.425, 'grad_norm': 13.031038284301758, 'learning_rate': 9.571704955496178e-06, 'epoch': 5.28}\n",
      "{'loss': 0.3992, 'grad_norm': 0.014390562660992146, 'learning_rate': 9.562064312733883e-06, 'epoch': 5.32}\n",
      "{'loss': 0.381, 'grad_norm': 36.41091537475586, 'learning_rate': 9.552332879194013e-06, 'epoch': 5.36}\n",
      "{'loss': 0.4147, 'grad_norm': 0.0007305230246856809, 'learning_rate': 9.54251084965987e-06, 'epoch': 5.41}\n",
      "{'loss': 0.4044, 'grad_norm': 7.178845405578613, 'learning_rate': 9.532598420728111e-06, 'epoch': 5.45}\n",
      "{'loss': 0.4011, 'grad_norm': 0.03416983038187027, 'learning_rate': 9.52259579080482e-06, 'epoch': 5.49}\n",
      "{'loss': 0.3992, 'grad_norm': 124.52642059326172, 'learning_rate': 9.512503160101537e-06, 'epoch': 5.53}\n",
      "{'loss': 0.3943, 'grad_norm': 31.69277572631836, 'learning_rate': 9.502341184974178e-06, 'epoch': 5.57}\n",
      "{'loss': 0.4789, 'grad_norm': 5.395389080047607, 'learning_rate': 9.492069339532568e-06, 'epoch': 5.61}\n",
      "{'loss': 0.3776, 'grad_norm': 6.62662410736084, 'learning_rate': 9.48170810432504e-06, 'epoch': 5.65}\n",
      "{'loss': 0.3853, 'grad_norm': 0.17836520075798035, 'learning_rate': 9.471257686740935e-06, 'epoch': 5.69}\n",
      "{'loss': 0.4714, 'grad_norm': 0.020269986242055893, 'learning_rate': 9.460718295954655e-06, 'epoch': 5.73}\n",
      "{'loss': 0.3704, 'grad_norm': 0.0001700219145277515, 'learning_rate': 9.450090142921488e-06, 'epoch': 5.77}\n",
      "{'loss': 0.4099, 'grad_norm': 23.88021469116211, 'learning_rate': 9.439394962008598e-06, 'epoch': 5.81}\n",
      "{'loss': 0.4145, 'grad_norm': 207.74327087402344, 'learning_rate': 9.428590100904632e-06, 'epoch': 5.86}\n",
      "{'loss': 0.4116, 'grad_norm': 20.639209747314453, 'learning_rate': 9.417697120628178e-06, 'epoch': 5.9}\n",
      "{'loss': 0.418, 'grad_norm': 111.095458984375, 'learning_rate': 9.406716239211928e-06, 'epoch': 5.94}\n",
      "{'loss': 0.4128, 'grad_norm': 4.217218399047852, 'learning_rate': 9.395647676447995e-06, 'epoch': 5.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960e27d63f904adcbf6bed06f334d817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7378344406536183, 'eval_f1': 0.7380182134283241, 'eval_loss': 2.8153841495513916, 'eval_runtime': 201.1419, 'eval_samples_per_second': 27.687, 'eval_steps_per_second': 9.232, 'epoch': 6.0}\n",
      "{'loss': 0.3366, 'grad_norm': 0.09641409665346146, 'learning_rate': 9.38451405306539e-06, 'epoch': 6.02}\n",
      "{'loss': 0.3111, 'grad_norm': 113.77236938476562, 'learning_rate': 9.373270968247057e-06, 'epoch': 6.06}\n",
      "{'loss': 0.2934, 'grad_norm': 0.014636972919106483, 'learning_rate': 9.36194087151789e-06, 'epoch': 6.1}\n",
      "{'loss': 0.3182, 'grad_norm': 49.406951904296875, 'learning_rate': 9.35054690988353e-06, 'epoch': 6.14}\n",
      "{'loss': 0.3, 'grad_norm': 0.0, 'learning_rate': 9.339043644299678e-06, 'epoch': 6.18}\n",
      "{'loss': 0.2844, 'grad_norm': 1.376763105392456, 'learning_rate': 9.327454051895331e-06, 'epoch': 6.22}\n",
      "{'loss': 0.3343, 'grad_norm': 29.912090301513672, 'learning_rate': 9.315778364646489e-06, 'epoch': 6.27}\n",
      "{'loss': 0.3035, 'grad_norm': 0.0032012274023145437, 'learning_rate': 9.30401681625242e-06, 'epoch': 6.31}\n",
      "{'loss': 0.3499, 'grad_norm': 7.482961654663086, 'learning_rate': 9.292169642130979e-06, 'epoch': 6.35}\n",
      "{'loss': 0.3362, 'grad_norm': 3.0409168516598584e-07, 'learning_rate': 9.280261029598679e-06, 'epoch': 6.39}\n",
      "{'loss': 0.3406, 'grad_norm': 0.7140049338340759, 'learning_rate': 9.268243487186819e-06, 'epoch': 6.43}\n",
      "{'loss': 0.3483, 'grad_norm': 0.532989501953125, 'learning_rate': 9.25614103508259e-06, 'epoch': 6.47}\n",
      "{'loss': 0.3346, 'grad_norm': 105.87914276123047, 'learning_rate': 9.243953915527338e-06, 'epoch': 6.51}\n",
      "{'loss': 0.3346, 'grad_norm': 213.89952087402344, 'learning_rate': 9.231682372457101e-06, 'epoch': 6.55}\n",
      "{'loss': 0.3517, 'grad_norm': 0.004013885743916035, 'learning_rate': 9.219326651497734e-06, 'epoch': 6.59}\n",
      "{'loss': 0.3645, 'grad_norm': 90.7846908569336, 'learning_rate': 9.20688699995998e-06, 'epoch': 6.63}\n",
      "{'loss': 0.2742, 'grad_norm': 0.0, 'learning_rate': 9.194363666834533e-06, 'epoch': 6.67}\n",
      "{'loss': 0.3397, 'grad_norm': 0.008595801889896393, 'learning_rate': 9.181756902787045e-06, 'epoch': 6.72}\n",
      "{'loss': 0.3337, 'grad_norm': 0.24711357057094574, 'learning_rate': 9.16909242288206e-06, 'epoch': 6.76}\n",
      "{'loss': 0.3819, 'grad_norm': 0.030023474246263504, 'learning_rate': 9.156345349249594e-06, 'epoch': 6.8}\n",
      "{'loss': 0.3495, 'grad_norm': 0.022467192262411118, 'learning_rate': 9.143490143268289e-06, 'epoch': 6.84}\n",
      "{'loss': 0.3743, 'grad_norm': 1.6971029253909364e-05, 'learning_rate': 9.130552524643773e-06, 'epoch': 6.88}\n",
      "{'loss': 0.3117, 'grad_norm': 0.0007346820784732699, 'learning_rate': 9.117532752333992e-06, 'epoch': 6.92}\n",
      "{'loss': 0.3279, 'grad_norm': 31.313005447387695, 'learning_rate': 9.104431086941275e-06, 'epoch': 6.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300cc8738c84445aabe8f8bf733a96f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7468127132339738, 'eval_f1': 0.7473271720318707, 'eval_loss': 2.859309673309326, 'eval_runtime': 198.1486, 'eval_samples_per_second': 28.105, 'eval_steps_per_second': 9.372, 'epoch': 7.0}\n",
      "{'loss': 0.3291, 'grad_norm': 41.77672576904297, 'learning_rate': 9.091247790707105e-06, 'epoch': 7.0}\n",
      "{'loss': 0.2861, 'grad_norm': 181.09593200683594, 'learning_rate': 9.077983127506887e-06, 'epoch': 7.04}\n",
      "{'loss': 0.2967, 'grad_norm': 0.0, 'learning_rate': 9.064637362844655e-06, 'epoch': 7.08}\n",
      "{'loss': 0.228, 'grad_norm': 2.737609747782699e-07, 'learning_rate': 9.051210763847759e-06, 'epoch': 7.13}\n",
      "{'loss': 0.2277, 'grad_norm': 0.006323406007140875, 'learning_rate': 9.037730693815723e-06, 'epoch': 7.17}\n",
      "{'loss': 0.2629, 'grad_norm': 306.615966796875, 'learning_rate': 9.024170648871321e-06, 'epoch': 7.21}\n",
      "{'loss': 0.2806, 'grad_norm': 0.00042721349745988846, 'learning_rate': 9.010503485336517e-06, 'epoch': 7.25}\n",
      "{'loss': 0.2194, 'grad_norm': 22.81386375427246, 'learning_rate': 8.996756571004767e-06, 'epoch': 7.29}\n",
      "{'loss': 0.2733, 'grad_norm': 6.36584402968765e-08, 'learning_rate': 8.98293018103279e-06, 'epoch': 7.33}\n",
      "{'loss': 0.2565, 'grad_norm': 5.885330210730899e-06, 'learning_rate': 8.969024592168078e-06, 'epoch': 7.37}\n",
      "{'loss': 0.2556, 'grad_norm': 3.931300440740415e-08, 'learning_rate': 8.955068130339147e-06, 'epoch': 7.41}\n",
      "{'loss': 0.258, 'grad_norm': 132.90554809570312, 'learning_rate': 8.941005137267727e-06, 'epoch': 7.45}\n",
      "{'loss': 0.3113, 'grad_norm': 2.1916710224445524e-08, 'learning_rate': 8.926863784470619e-06, 'epoch': 7.49}\n",
      "{'loss': 0.2934, 'grad_norm': 7.716794789303094e-05, 'learning_rate': 8.912644354999584e-06, 'epoch': 7.53}\n",
      "{'loss': 0.2636, 'grad_norm': 209.47743225097656, 'learning_rate': 8.89834713346915e-06, 'epoch': 7.58}\n",
      "{'loss': 0.2667, 'grad_norm': 7.307332452910487e-06, 'learning_rate': 8.883972406050925e-06, 'epoch': 7.62}\n",
      "{'loss': 0.3466, 'grad_norm': 87.07654571533203, 'learning_rate': 8.869520460467866e-06, 'epoch': 7.66}\n",
      "{'loss': 0.2785, 'grad_norm': 0.0, 'learning_rate': 8.854991585988519e-06, 'epoch': 7.7}\n",
      "{'loss': 0.3765, 'grad_norm': 113.36672973632812, 'learning_rate': 8.840415360737123e-06, 'epoch': 7.74}\n",
      "{'loss': 0.2916, 'grad_norm': 109.1523208618164, 'learning_rate': 8.825733654822941e-06, 'epoch': 7.78}\n",
      "{'loss': 0.2945, 'grad_norm': 0.0, 'learning_rate': 8.81097589644434e-06, 'epoch': 7.82}\n",
      "{'loss': 0.3307, 'grad_norm': 43.36070251464844, 'learning_rate': 8.796142380990981e-06, 'epoch': 7.86}\n",
      "{'loss': 0.3275, 'grad_norm': 0.006451887544244528, 'learning_rate': 8.78126329843127e-06, 'epoch': 7.9}\n",
      "{'loss': 0.2918, 'grad_norm': 0.22885070741176605, 'learning_rate': 8.766279311081507e-06, 'epoch': 7.94}\n",
      "{'loss': 0.2867, 'grad_norm': 0.0, 'learning_rate': 8.751220461298907e-06, 'epoch': 7.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9c4d14569c4a6f8d687ebbc9668cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7502244568145089, 'eval_f1': 0.7508060164511579, 'eval_loss': 3.370340347290039, 'eval_runtime': 198.031, 'eval_samples_per_second': 28.122, 'eval_steps_per_second': 9.377, 'epoch': 8.0}\n",
      "{'loss': 0.2375, 'grad_norm': 0.0, 'learning_rate': 8.736087050499739e-06, 'epoch': 8.03}\n",
      "{'loss': 0.2354, 'grad_norm': 9.699722431832924e-05, 'learning_rate': 8.720909870838018e-06, 'epoch': 8.07}\n",
      "{'loss': 0.2151, 'grad_norm': 0.009008158929646015, 'learning_rate': 8.705628395820758e-06, 'epoch': 8.11}\n",
      "{'loss': 0.2529, 'grad_norm': 0.07475809752941132, 'learning_rate': 8.690273272352683e-06, 'epoch': 8.15}\n",
      "{'loss': 0.1988, 'grad_norm': 0.010351685807108879, 'learning_rate': 8.674844807780247e-06, 'epoch': 8.19}\n",
      "{'loss': 0.2449, 'grad_norm': 0.0, 'learning_rate': 8.659343310917898e-06, 'epoch': 8.23}\n",
      "{'loss': 0.2409, 'grad_norm': 8.283504548955989e-09, 'learning_rate': 8.64376909204188e-06, 'epoch': 8.27}\n",
      "{'loss': 0.2424, 'grad_norm': 332.6899108886719, 'learning_rate': 8.628153828199898e-06, 'epoch': 8.31}\n",
      "{'loss': 0.2534, 'grad_norm': 0.00015632380382157862, 'learning_rate': 8.612435245822127e-06, 'epoch': 8.35}\n",
      "{'loss': 0.1898, 'grad_norm': 0.0032157767564058304, 'learning_rate': 8.59664488033734e-06, 'epoch': 8.39}\n",
      "{'loss': 0.281, 'grad_norm': 6.831605787738226e-06, 'learning_rate': 8.580783047803754e-06, 'epoch': 8.44}\n",
      "{'loss': 0.241, 'grad_norm': 0.14295406639575958, 'learning_rate': 8.564850065710053e-06, 'epoch': 8.48}\n",
      "{'loss': 0.2582, 'grad_norm': 0.39972785115242004, 'learning_rate': 8.54884625296905e-06, 'epoch': 8.52}\n",
      "{'loss': 0.2111, 'grad_norm': 0.03254573419690132, 'learning_rate': 8.532771929911292e-06, 'epoch': 8.56}\n",
      "{'loss': 0.3045, 'grad_norm': 0.2802843153476715, 'learning_rate': 8.516627418278655e-06, 'epoch': 8.6}\n",
      "{'loss': 0.2801, 'grad_norm': 0.0, 'learning_rate': 8.500413041217904e-06, 'epoch': 8.64}\n",
      "{'loss': 0.2946, 'grad_norm': 34.165889739990234, 'learning_rate': 8.484161760295497e-06, 'epoch': 8.68}\n",
      "{'loss': 0.2691, 'grad_norm': 6.528435392283427e-08, 'learning_rate': 8.467808765509664e-06, 'epoch': 8.72}\n",
      "{'loss': 0.194, 'grad_norm': 0.0, 'learning_rate': 8.451419794742865e-06, 'epoch': 8.76}\n",
      "{'loss': 0.3244, 'grad_norm': 0.5880877375602722, 'learning_rate': 8.434929488887133e-06, 'epoch': 8.8}\n",
      "{'loss': 0.2624, 'grad_norm': 1.6820921189264482e-07, 'learning_rate': 8.41837095286002e-06, 'epoch': 8.85}\n",
      "{'loss': 0.247, 'grad_norm': 0.0, 'learning_rate': 8.401744518095354e-06, 'epoch': 8.89}\n",
      "{'loss': 0.2312, 'grad_norm': 0.010241495445370674, 'learning_rate': 8.38505051738602e-06, 'epoch': 8.93}\n",
      "{'loss': 0.2885, 'grad_norm': 33.37345504760742, 'learning_rate': 8.368289284877291e-06, 'epoch': 8.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942628d9d23e4666a40b88534828c031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7482492368468306, 'eval_f1': 0.749095716452519, 'eval_loss': 3.509242057800293, 'eval_runtime': 198.2173, 'eval_samples_per_second': 28.095, 'eval_steps_per_second': 9.369, 'epoch': 9.0}\n",
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "{'train_runtime': 41967.0007, 'train_samples_per_second': 26.185, 'train_steps_per_second': 8.728, 'train_loss': 0.5861232054614318, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f249a50a104e5a9e5f99644ddabeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 06:56:41,566] Trial 0 finished with value: 0.7502244568145089 and parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.0052258285035737e-05, 'batch_size': 3, 'warmup_ratio': 0.04149176551014211, 'weight_decay': 0.006685281279171756, 'adam_beta1': 0.9429922176765829, 'adam_beta2': 0.9918592948813898, 'adam_epsilon': 8.867767549079712e-08, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.7502244568145089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Trial 1 parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 4.8886290767341015e-06, 'batch_size': 3, 'warmup_ratio': 0.16186847722025877, 'weight_decay': 0.05903318728752488, 'adam_beta1': 0.937696247322504, 'adam_beta2': 0.996044065187816, 'adam_epsilon': 4.23565621962841e-07, 'lr_scheduler_type': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892c5de8eb0649eb896604ed160c6555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6131, 'grad_norm': 2.6973414421081543, 'learning_rate': 4.12243357287884e-08, 'epoch': 0.04}\n",
      "{'loss': 1.6112, 'grad_norm': 2.8102755546569824, 'learning_rate': 8.24486714575768e-08, 'epoch': 0.08}\n",
      "{'loss': 1.6114, 'grad_norm': 1.8595918416976929, 'learning_rate': 1.2367300718636522e-07, 'epoch': 0.12}\n",
      "{'loss': 1.6116, 'grad_norm': 2.2786362171173096, 'learning_rate': 1.648973429151536e-07, 'epoch': 0.16}\n",
      "{'loss': 1.6107, 'grad_norm': 2.2921807765960693, 'learning_rate': 2.0603922997248442e-07, 'epoch': 0.2}\n",
      "{'loss': 1.6109, 'grad_norm': 2.394362211227417, 'learning_rate': 2.4726356570127284e-07, 'epoch': 0.25}\n",
      "{'loss': 1.6063, 'grad_norm': 1.938875675201416, 'learning_rate': 2.8848790143006125e-07, 'epoch': 0.29}\n",
      "{'loss': 1.5947, 'grad_norm': 2.3115158081054688, 'learning_rate': 3.297122371588496e-07, 'epoch': 0.33}\n",
      "{'loss': 1.5724, 'grad_norm': 2.8948936462402344, 'learning_rate': 3.7085412421618043e-07, 'epoch': 0.37}\n",
      "{'loss': 1.5195, 'grad_norm': 2.791253089904785, 'learning_rate': 4.1191356260205375e-07, 'epoch': 0.41}\n",
      "{'loss': 1.405, 'grad_norm': 4.847089767456055, 'learning_rate': 4.5313789833084217e-07, 'epoch': 0.45}\n",
      "{'loss': 1.3503, 'grad_norm': 7.7034993171691895, 'learning_rate': 4.943622340596306e-07, 'epoch': 0.49}\n",
      "{'loss': 1.3345, 'grad_norm': 11.127699851989746, 'learning_rate': 5.355041211169614e-07, 'epoch': 0.53}\n",
      "{'loss': 1.3255, 'grad_norm': 9.6265287399292, 'learning_rate': 5.767284568457498e-07, 'epoch': 0.57}\n",
      "{'loss': 1.3046, 'grad_norm': 13.42325496673584, 'learning_rate': 6.179527925745381e-07, 'epoch': 0.61}\n",
      "{'loss': 1.2775, 'grad_norm': 8.146121978759766, 'learning_rate': 6.59094679631869e-07, 'epoch': 0.66}\n",
      "{'loss': 1.2624, 'grad_norm': 34.662418365478516, 'learning_rate': 7.003190153606574e-07, 'epoch': 0.7}\n",
      "{'loss': 1.2575, 'grad_norm': 65.31287384033203, 'learning_rate': 7.415433510894459e-07, 'epoch': 0.74}\n",
      "{'loss': 1.2371, 'grad_norm': 33.602203369140625, 'learning_rate': 7.827676868182342e-07, 'epoch': 0.78}\n",
      "{'loss': 1.2335, 'grad_norm': 10.614776611328125, 'learning_rate': 8.239920225470227e-07, 'epoch': 0.82}\n",
      "{'loss': 1.256, 'grad_norm': 15.904643058776855, 'learning_rate': 8.65216358275811e-07, 'epoch': 0.86}\n",
      "{'loss': 1.2548, 'grad_norm': 7.559508800506592, 'learning_rate': 9.064406940045994e-07, 'epoch': 0.9}\n",
      "{'loss': 1.2262, 'grad_norm': 9.127202033996582, 'learning_rate': 9.475825810619302e-07, 'epoch': 0.94}\n",
      "{'loss': 1.2242, 'grad_norm': 15.240666389465332, 'learning_rate': 9.888069167907187e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f9454423184a6c95ef15e5f63e2c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.47333453043634405, 'eval_f1': 0.46485644354146954, 'eval_loss': 1.2072120904922485, 'eval_runtime': 197.9354, 'eval_samples_per_second': 28.135, 'eval_steps_per_second': 9.382, 'epoch': 1.0}\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.55\n",
      "{'train_runtime': 4628.5401, 'train_samples_per_second': 237.418, 'train_steps_per_second': 79.139, 'train_loss': 1.4092880261520397, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bedc6f249d44f7a6b2421d560212c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 08:17:09,633] Trial 1 finished with value: 0.47333453043634405 and parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 4.8886290767341015e-06, 'batch_size': 3, 'warmup_ratio': 0.16186847722025877, 'weight_decay': 0.05903318728752488, 'adam_beta1': 0.937696247322504, 'adam_beta2': 0.996044065187816, 'adam_epsilon': 4.23565621962841e-07, 'lr_scheduler_type': 'linear'}. Best is trial 0 with value: 0.7502244568145089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.55\n",
      "Current Trial 2 parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.2071681928297671e-06, 'batch_size': 3, 'warmup_ratio': 0.05481409846645513, 'weight_decay': 0.19033797329643962, 'adam_beta1': 0.8110259073487472, 'adam_beta2': 0.9918539826630653, 'adam_epsilon': 8.473115495344218e-07, 'lr_scheduler_type': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddc890e70e74b41b9b9870e0bf0b696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6083, 'grad_norm': 2.6217617988586426, 'learning_rate': 3.006046598012269e-08, 'epoch': 0.04}\n",
      "{'loss': 1.6121, 'grad_norm': 2.550875663757324, 'learning_rate': 6.012093196024539e-08, 'epoch': 0.08}\n",
      "{'loss': 1.6111, 'grad_norm': 1.7937190532684326, 'learning_rate': 9.018139794036808e-08, 'epoch': 0.12}\n",
      "{'loss': 1.6093, 'grad_norm': 2.191602945327759, 'learning_rate': 1.2024186392049077e-07, 'epoch': 0.16}\n",
      "{'loss': 1.6096, 'grad_norm': 2.2310688495635986, 'learning_rate': 1.5024220896865324e-07, 'epoch': 0.2}\n",
      "{'loss': 1.6101, 'grad_norm': 2.20054292678833, 'learning_rate': 1.8030267494877593e-07, 'epoch': 0.25}\n",
      "{'loss': 1.6068, 'grad_norm': 1.822987675666809, 'learning_rate': 2.1036314092889862e-07, 'epoch': 0.29}\n",
      "{'loss': 1.5943, 'grad_norm': 2.4202075004577637, 'learning_rate': 2.4036348597706103e-07, 'epoch': 0.33}\n",
      "{'loss': 1.5653, 'grad_norm': 3.0556869506835938, 'learning_rate': 2.703638310252235e-07, 'epoch': 0.37}\n",
      "{'loss': 1.5182, 'grad_norm': 4.583386421203613, 'learning_rate': 3.004242970053462e-07, 'epoch': 0.41}\n",
      "{'loss': 1.4443, 'grad_norm': 3.892232894897461, 'learning_rate': 3.3042464205350863e-07, 'epoch': 0.45}\n",
      "{'loss': 1.3774, 'grad_norm': 10.297099113464355, 'learning_rate': 3.604851080336313e-07, 'epoch': 0.49}\n",
      "{'loss': 1.3305, 'grad_norm': 9.266765594482422, 'learning_rate': 3.9048545308179376e-07, 'epoch': 0.53}\n",
      "{'loss': 1.2979, 'grad_norm': 11.161041259765625, 'learning_rate': 4.205459190619165e-07, 'epoch': 0.57}\n",
      "{'loss': 1.2766, 'grad_norm': 10.59521770477295, 'learning_rate': 4.5060638504203914e-07, 'epoch': 0.61}\n",
      "{'loss': 1.2374, 'grad_norm': 9.285622596740723, 'learning_rate': 4.806668510221618e-07, 'epoch': 0.66}\n",
      "{'loss': 1.2415, 'grad_norm': 16.59183120727539, 'learning_rate': 5.106070751383641e-07, 'epoch': 0.7}\n",
      "{'loss': 1.2461, 'grad_norm': 12.543286323547363, 'learning_rate': 5.406675411184867e-07, 'epoch': 0.74}\n",
      "{'loss': 1.2247, 'grad_norm': 8.513683319091797, 'learning_rate': 5.707280070986095e-07, 'epoch': 0.78}\n",
      "{'loss': 1.223, 'grad_norm': 17.481903076171875, 'learning_rate': 6.007884730787322e-07, 'epoch': 0.82}\n",
      "{'loss': 1.2208, 'grad_norm': 20.881052017211914, 'learning_rate': 6.307888181268946e-07, 'epoch': 0.86}\n",
      "{'loss': 1.2432, 'grad_norm': 26.02606964111328, 'learning_rate': 6.608492841070173e-07, 'epoch': 0.9}\n",
      "{'loss': 1.2046, 'grad_norm': 11.645373344421387, 'learning_rate': 6.909097500871399e-07, 'epoch': 0.94}\n",
      "{'loss': 1.2009, 'grad_norm': 18.934831619262695, 'learning_rate': 7.209702160672626e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704bb5e70d75487daff2c3a20bf73ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.47890105943616446, 'eval_f1': 0.4693392141291574, 'eval_loss': 1.0519323348999023, 'eval_runtime': 198.38, 'eval_samples_per_second': 28.072, 'eval_steps_per_second': 9.361, 'epoch': 1.0}\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.55\n",
      "{'train_runtime': 4629.2748, 'train_samples_per_second': 237.381, 'train_steps_per_second': 79.127, 'train_loss': 1.4012747424826282, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2960f4ec076746caa3b9c698b03a5371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 09:37:38,567] Trial 2 finished with value: 0.47890105943616446 and parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.2071681928297671e-06, 'batch_size': 3, 'warmup_ratio': 0.05481409846645513, 'weight_decay': 0.19033797329643962, 'adam_beta1': 0.8110259073487472, 'adam_beta2': 0.9918539826630653, 'adam_epsilon': 8.473115495344218e-07, 'lr_scheduler_type': 'linear'}. Best is trial 0 with value: 0.7502244568145089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.55\n",
      "Current Trial 3 parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.6121626433295556e-05, 'batch_size': 3, 'warmup_ratio': 0.8536227767441532, 'weight_decay': 0.008511306197269641, 'adam_beta1': 0.8900000550612733, 'adam_beta2': 0.9911201422338355, 'adam_epsilon': 2.835386956775334e-07, 'lr_scheduler_type': 'cosine'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af94c11123b4364a131644ce59c9beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6083, 'grad_norm': 2.621523141860962, 'learning_rate': 2.577950581466782e-08, 'epoch': 0.04}\n",
      "{'loss': 1.6121, 'grad_norm': 2.5507566928863525, 'learning_rate': 5.155901162933564e-08, 'epoch': 0.08}\n",
      "{'loss': 1.6112, 'grad_norm': 1.7942177057266235, 'learning_rate': 7.733851744400346e-08, 'epoch': 0.12}\n",
      "{'loss': 1.6094, 'grad_norm': 2.191884756088257, 'learning_rate': 1.0311802325867128e-07, 'epoch': 0.16}\n",
      "{'loss': 1.6097, 'grad_norm': 2.2317261695861816, 'learning_rate': 1.2884597006170975e-07, 'epoch': 0.2}\n",
      "{'loss': 1.6103, 'grad_norm': 2.197389602661133, 'learning_rate': 1.5462547587637758e-07, 'epoch': 0.25}\n",
      "{'loss': 1.6078, 'grad_norm': 1.7647435665130615, 'learning_rate': 1.8040498169104541e-07, 'epoch': 0.29}\n",
      "{'loss': 1.6029, 'grad_norm': 2.2723753452301025, 'learning_rate': 2.061329284940839e-07, 'epoch': 0.33}\n",
      "{'loss': 1.5818, 'grad_norm': 2.453111410140991, 'learning_rate': 2.3191243430875172e-07, 'epoch': 0.37}\n",
      "{'loss': 1.5479, 'grad_norm': 6.33663272857666, 'learning_rate': 2.576403811117902e-07, 'epoch': 0.41}\n",
      "{'loss': 1.4959, 'grad_norm': 2.834568500518799, 'learning_rate': 2.8341988692645805e-07, 'epoch': 0.45}\n",
      "{'loss': 1.4314, 'grad_norm': 7.5692138671875, 'learning_rate': 3.091478337294965e-07, 'epoch': 0.49}\n",
      "{'loss': 1.3685, 'grad_norm': 7.31424617767334, 'learning_rate': 3.34875780532535e-07, 'epoch': 0.53}\n",
      "{'loss': 1.3287, 'grad_norm': 11.183451652526855, 'learning_rate': 3.6065528634720283e-07, 'epoch': 0.57}\n",
      "{'loss': 1.2993, 'grad_norm': 9.482887268066406, 'learning_rate': 3.8643479216187066e-07, 'epoch': 0.61}\n",
      "{'loss': 1.2624, 'grad_norm': 7.5488200187683105, 'learning_rate': 4.1221429797653844e-07, 'epoch': 0.66}\n",
      "{'loss': 1.2575, 'grad_norm': 25.123302459716797, 'learning_rate': 4.378906857679476e-07, 'epoch': 0.7}\n",
      "{'loss': 1.2532, 'grad_norm': 10.39833927154541, 'learning_rate': 4.636701915826154e-07, 'epoch': 0.74}\n",
      "{'loss': 1.2313, 'grad_norm': 7.905008792877197, 'learning_rate': 4.894496973972832e-07, 'epoch': 0.78}\n",
      "{'loss': 1.2261, 'grad_norm': 14.69491195678711, 'learning_rate': 5.152292032119512e-07, 'epoch': 0.82}\n",
      "{'loss': 1.226, 'grad_norm': 13.873373031616211, 'learning_rate': 5.409571500149895e-07, 'epoch': 0.86}\n",
      "{'loss': 1.2511, 'grad_norm': 30.17266845703125, 'learning_rate': 5.667366558296573e-07, 'epoch': 0.9}\n",
      "{'loss': 1.2086, 'grad_norm': 13.558140754699707, 'learning_rate': 5.925161616443252e-07, 'epoch': 0.94}\n",
      "{'loss': 1.2037, 'grad_norm': 19.043729782104492, 'learning_rate': 6.18295667458993e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a3c139f03d4644837c072e5203b8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.4794397557909858, 'eval_f1': 0.46846660851158545, 'eval_loss': 1.0552749633789062, 'eval_runtime': 197.8134, 'eval_samples_per_second': 28.153, 'eval_steps_per_second': 9.388, 'epoch': 1.0}\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.55\n",
      "{'train_runtime': 4628.1028, 'train_samples_per_second': 237.441, 'train_steps_per_second': 79.147, 'train_loss': 1.4150087523714232, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87cd1e114d04b99b557563ec8bdf874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 10:58:06,202] Trial 3 finished with value: 0.4794397557909858 and parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.6121626433295556e-05, 'batch_size': 3, 'warmup_ratio': 0.8536227767441532, 'weight_decay': 0.008511306197269641, 'adam_beta1': 0.8900000550612733, 'adam_beta2': 0.9911201422338355, 'adam_epsilon': 2.835386956775334e-07, 'lr_scheduler_type': 'cosine'}. Best is trial 0 with value: 0.7502244568145089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Trial 4 parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 8.510498126281366e-05, 'batch_size': 3, 'warmup_ratio': 0.1846444928659816, 'weight_decay': 0.03194884679149762, 'adam_beta1': 0.8399822335829173, 'adam_beta2': 0.9972014587399104, 'adam_epsilon': 3.0019466308568936e-07, 'lr_scheduler_type': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf79f0bebb24ee48941be9ecb8b0820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6082, 'grad_norm': 2.626997709274292, 'learning_rate': 6.291396686883735e-07, 'epoch': 0.04}\n",
      "{'loss': 1.5825, 'grad_norm': 3.6077518463134766, 'learning_rate': 1.2570210580393702e-06, 'epoch': 0.08}\n",
      "{'loss': 1.3131, 'grad_norm': 16.349205017089844, 'learning_rate': 1.8823858887156135e-06, 'epoch': 0.12}\n",
      "{'loss': 1.2578, 'grad_norm': 14.608709335327148, 'learning_rate': 2.5115255574039867e-06, 'epoch': 0.16}\n",
      "{'loss': 1.2403, 'grad_norm': 13.00022029876709, 'learning_rate': 3.14066522609236e-06, 'epoch': 0.2}\n",
      "{'loss': 1.2054, 'grad_norm': 46.618072509765625, 'learning_rate': 3.769804894780734e-06, 'epoch': 0.25}\n",
      "{'loss': 1.2028, 'grad_norm': 35.32038116455078, 'learning_rate': 4.397686284131731e-06, 'epoch': 0.29}\n",
      "{'loss': 1.1724, 'grad_norm': 16.501367568969727, 'learning_rate': 5.026825952820104e-06, 'epoch': 0.33}\n",
      "{'loss': 1.1622, 'grad_norm': 23.571575164794922, 'learning_rate': 5.6559656215084775e-06, 'epoch': 0.37}\n",
      "{'loss': 1.1665, 'grad_norm': 34.79861068725586, 'learning_rate': 6.285105290196851e-06, 'epoch': 0.41}\n",
      "{'loss': 1.1639, 'grad_norm': 17.685752868652344, 'learning_rate': 6.914244958885225e-06, 'epoch': 0.45}\n",
      "{'loss': 1.1507, 'grad_norm': 13.754340171813965, 'learning_rate': 7.543384627573598e-06, 'epoch': 0.49}\n",
      "{'loss': 1.1423, 'grad_norm': 8.222532272338867, 'learning_rate': 8.172524296261971e-06, 'epoch': 0.53}\n",
      "{'loss': 1.1505, 'grad_norm': 15.020258903503418, 'learning_rate': 8.800405685612969e-06, 'epoch': 0.57}\n",
      "{'loss': 1.1375, 'grad_norm': 12.764762878417969, 'learning_rate': 9.429545354301342e-06, 'epoch': 0.61}\n",
      "{'loss': 1.0981, 'grad_norm': 10.938939094543457, 'learning_rate': 1.0058685022989714e-05, 'epoch': 0.66}\n",
      "{'loss': 1.0731, 'grad_norm': 15.473215103149414, 'learning_rate': 1.0687824691678089e-05, 'epoch': 0.7}\n",
      "{'loss': 1.1388, 'grad_norm': 9.413698196411133, 'learning_rate': 1.1316964360366463e-05, 'epoch': 0.74}\n",
      "{'loss': 1.0463, 'grad_norm': 28.81051254272461, 'learning_rate': 1.1946104029054836e-05, 'epoch': 0.78}\n",
      "{'loss': 1.0762, 'grad_norm': 15.858640670776367, 'learning_rate': 1.2575243697743208e-05, 'epoch': 0.82}\n",
      "{'loss': 1.0861, 'grad_norm': 34.027130126953125, 'learning_rate': 1.3204383366431581e-05, 'epoch': 0.86}\n",
      "{'loss': 1.0784, 'grad_norm': 18.69070053100586, 'learning_rate': 1.3832264755782579e-05, 'epoch': 0.9}\n",
      "{'loss': 1.0542, 'grad_norm': 7.746912479400635, 'learning_rate': 1.4461404424470952e-05, 'epoch': 0.94}\n",
      "{'loss': 1.0398, 'grad_norm': 12.906351089477539, 'learning_rate': 1.5090544093159327e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c895f367b99483c9587845eb15f19cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.60782905369007, 'eval_f1': 0.605538625314635, 'eval_loss': 1.1023038625717163, 'eval_runtime': 203.5403, 'eval_samples_per_second': 27.361, 'eval_steps_per_second': 9.124, 'epoch': 1.0}\n",
      "{'loss': 1.0083, 'grad_norm': 3.4299256801605225, 'learning_rate': 1.5718425482510323e-05, 'epoch': 1.02}\n",
      "{'loss': 0.9612, 'grad_norm': 4.2197747230529785, 'learning_rate': 1.6347565151198698e-05, 'epoch': 1.06}\n",
      "{'loss': 0.9746, 'grad_norm': 23.688749313354492, 'learning_rate': 1.697670481988707e-05, 'epoch': 1.11}\n",
      "{'loss': 0.9784, 'grad_norm': 30.733102798461914, 'learning_rate': 1.7605844488575445e-05, 'epoch': 1.15}\n",
      "{'loss': 0.969, 'grad_norm': 26.562522888183594, 'learning_rate': 1.8232467598589065e-05, 'epoch': 1.19}\n",
      "{'loss': 0.9833, 'grad_norm': 14.277809143066406, 'learning_rate': 1.8861607267277436e-05, 'epoch': 1.23}\n",
      "{'loss': 0.9787, 'grad_norm': 12.162018775939941, 'learning_rate': 1.949074693596581e-05, 'epoch': 1.27}\n",
      "{'loss': 0.9745, 'grad_norm': 56.56035232543945, 'learning_rate': 2.0119886604654183e-05, 'epoch': 1.31}\n",
      "{'loss': 0.9269, 'grad_norm': 12.012189865112305, 'learning_rate': 2.074902627334256e-05, 'epoch': 1.35}\n",
      "{'loss': 0.9448, 'grad_norm': 5.705605983734131, 'learning_rate': 2.137816594203093e-05, 'epoch': 1.39}\n",
      "{'loss': 0.9208, 'grad_norm': 50.84130096435547, 'learning_rate': 2.2006047331381926e-05, 'epoch': 1.43}\n",
      "{'loss': 0.937, 'grad_norm': 19.559349060058594, 'learning_rate': 2.26351870000703e-05, 'epoch': 1.47}\n",
      "{'loss': 0.9578, 'grad_norm': 54.061241149902344, 'learning_rate': 2.3264326668758673e-05, 'epoch': 1.52}\n",
      "{'loss': 0.9552, 'grad_norm': 14.680898666381836, 'learning_rate': 2.3893466337447048e-05, 'epoch': 1.56}\n",
      "{'loss': 0.9635, 'grad_norm': 13.674894332885742, 'learning_rate': 2.452260600613542e-05, 'epoch': 1.6}\n",
      "{'loss': 0.9152, 'grad_norm': 1.41334068775177, 'learning_rate': 2.515174567482379e-05, 'epoch': 1.64}\n",
      "{'loss': 0.9448, 'grad_norm': 51.19849395751953, 'learning_rate': 2.5780885343512167e-05, 'epoch': 1.68}\n",
      "{'loss': 0.9411, 'grad_norm': 4.556741237640381, 'learning_rate': 2.6408766732863162e-05, 'epoch': 1.72}\n",
      "{'loss': 0.9533, 'grad_norm': 16.44084358215332, 'learning_rate': 2.7037906401551538e-05, 'epoch': 1.76}\n",
      "{'loss': 0.9532, 'grad_norm': 29.310588836669922, 'learning_rate': 2.7667046070239913e-05, 'epoch': 1.8}\n",
      "{'loss': 0.959, 'grad_norm': 57.475852966308594, 'learning_rate': 2.8296185738928288e-05, 'epoch': 1.84}\n",
      "{'loss': 0.9357, 'grad_norm': 25.024158477783203, 'learning_rate': 2.8924067128279284e-05, 'epoch': 1.88}\n",
      "{'loss': 0.9397, 'grad_norm': 7.75481653213501, 'learning_rate': 2.955320679696766e-05, 'epoch': 1.92}\n",
      "{'loss': 0.9379, 'grad_norm': 13.061766624450684, 'learning_rate': 3.018234646565603e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e17b21dd5d944bf92aa6e2ef7c31347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.6345843059795295, 'eval_f1': 0.6385157762164315, 'eval_loss': 0.9348210692405701, 'eval_runtime': 199.5858, 'eval_samples_per_second': 27.903, 'eval_steps_per_second': 9.304, 'epoch': 2.0}\n",
      "{'loss': 0.9012, 'grad_norm': 39.057472229003906, 'learning_rate': 3.08114861343444e-05, 'epoch': 2.01}\n",
      "{'loss': 0.7977, 'grad_norm': 0.15105409920215607, 'learning_rate': 3.14393675236954e-05, 'epoch': 2.05}\n",
      "{'loss': 0.8274, 'grad_norm': 44.4431266784668, 'learning_rate': 3.20672489130464e-05, 'epoch': 2.09}\n",
      "{'loss': 0.8255, 'grad_norm': 8.83962345123291, 'learning_rate': 3.269638858173477e-05, 'epoch': 2.13}\n",
      "{'loss': 0.8398, 'grad_norm': 55.83673095703125, 'learning_rate': 3.3325528250423144e-05, 'epoch': 2.17}\n",
      "{'loss': 0.8077, 'grad_norm': 26.992734909057617, 'learning_rate': 3.395466791911152e-05, 'epoch': 2.21}\n",
      "{'loss': 0.8549, 'grad_norm': 31.085447311401367, 'learning_rate': 3.458380758779989e-05, 'epoch': 2.25}\n",
      "{'loss': 0.8344, 'grad_norm': 3.28800892829895, 'learning_rate': 3.521294725648826e-05, 'epoch': 2.29}\n",
      "{'loss': 0.8885, 'grad_norm': 43.23609924316406, 'learning_rate': 3.5839570366501886e-05, 'epoch': 2.33}\n",
      "{'loss': 1.1687, 'grad_norm': 21.97939682006836, 'learning_rate': 3.6468710035190254e-05, 'epoch': 2.38}\n",
      "{'loss': 1.1469, 'grad_norm': 61.969120025634766, 'learning_rate': 3.709659142454126e-05, 'epoch': 2.42}\n",
      "{'loss': 0.9398, 'grad_norm': 38.874664306640625, 'learning_rate': 3.7725731093229625e-05, 'epoch': 2.46}\n",
      "{'loss': 0.8413, 'grad_norm': 30.142549514770508, 'learning_rate': 3.8354870761918e-05, 'epoch': 2.5}\n",
      "{'loss': 0.9717, 'grad_norm': 19.383939743041992, 'learning_rate': 3.8984010430606375e-05, 'epoch': 2.54}\n",
      "{'loss': 0.8917, 'grad_norm': 11.6967134475708, 'learning_rate': 3.9613150099294744e-05, 'epoch': 2.58}\n",
      "{'loss': 0.8796, 'grad_norm': 37.24570083618164, 'learning_rate': 4.024228976798312e-05, 'epoch': 2.62}\n",
      "{'loss': 0.8793, 'grad_norm': 5.472811698913574, 'learning_rate': 4.0871429436671494e-05, 'epoch': 2.66}\n",
      "{'loss': 0.8581, 'grad_norm': 10.676178932189941, 'learning_rate': 4.150056910535987e-05, 'epoch': 2.7}\n",
      "{'loss': 0.9068, 'grad_norm': 8.199978828430176, 'learning_rate': 4.212970877404824e-05, 'epoch': 2.74}\n",
      "{'loss': 0.8633, 'grad_norm': 42.54001998901367, 'learning_rate': 4.275759016339924e-05, 'epoch': 2.78}\n",
      "{'loss': 0.8946, 'grad_norm': 63.447364807128906, 'learning_rate': 4.338672983208761e-05, 'epoch': 2.83}\n",
      "{'loss': 0.9415, 'grad_norm': 17.675987243652344, 'learning_rate': 4.4015869500775984e-05, 'epoch': 2.87}\n",
      "{'loss': 0.931, 'grad_norm': 32.61122131347656, 'learning_rate': 4.464500916946436e-05, 'epoch': 2.91}\n",
      "{'loss': 0.9124, 'grad_norm': 27.522567749023438, 'learning_rate': 4.5271632279477975e-05, 'epoch': 2.95}\n",
      "{'loss': 0.9199, 'grad_norm': 15.27303695678711, 'learning_rate': 4.590077194816635e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc33adead4942838eb9539c4da690c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.456994074340097, 'eval_f1': 0.4436315212364236, 'eval_loss': 1.059770941734314, 'eval_runtime': 197.9261, 'eval_samples_per_second': 28.137, 'eval_steps_per_second': 9.382, 'epoch': 3.0}\n",
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "{'train_runtime': 14142.4415, 'train_samples_per_second': 77.702, 'train_steps_per_second': 25.901, 'train_loss': 1.0113622996054026, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f74fa6259442489a93582e931dccc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 14:57:08,687] Trial 4 finished with value: 0.6345843059795295 and parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 8.510498126281366e-05, 'batch_size': 3, 'warmup_ratio': 0.1846444928659816, 'weight_decay': 0.03194884679149762, 'adam_beta1': 0.8399822335829173, 'adam_beta2': 0.9972014587399104, 'adam_epsilon': 3.0019466308568936e-07, 'lr_scheduler_type': 'linear'}. Best is trial 0 with value: 0.7502244568145089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Current Trial 5 parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 2.0092610900045777e-05, 'batch_size': 3, 'warmup_ratio': 0.5940475933128249, 'weight_decay': 0.2165300105800973, 'adam_beta1': 0.9336589550502725, 'adam_beta2': 0.9904720666000915, 'adam_epsilon': 5.339974252727158e-07, 'lr_scheduler_type': 'cosine_with_restarts'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ae8a0481e543cebeba911fa0be7f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6102, 'grad_norm': 2.6346895694732666, 'learning_rate': 4.616868313429636e-08, 'epoch': 0.04}\n",
      "{'loss': 1.6103, 'grad_norm': 2.7047455310821533, 'learning_rate': 9.233736626859272e-08, 'epoch': 0.08}\n",
      "{'loss': 1.6112, 'grad_norm': 1.8697564601898193, 'learning_rate': 1.3850604940288908e-07, 'epoch': 0.12}\n",
      "{'loss': 1.6084, 'grad_norm': 2.0832273960113525, 'learning_rate': 1.8467473253718545e-07, 'epoch': 0.16}\n",
      "{'loss': 1.6112, 'grad_norm': 2.204847812652588, 'learning_rate': 2.3075107830521323e-07, 'epoch': 0.2}\n",
      "{'loss': 1.6114, 'grad_norm': 2.2089457511901855, 'learning_rate': 2.7691976143950957e-07, 'epoch': 0.25}\n",
      "{'loss': 1.61, 'grad_norm': 1.729021668434143, 'learning_rate': 3.2308844457380594e-07, 'epoch': 0.29}\n",
      "{'loss': 1.6102, 'grad_norm': 1.9967048168182373, 'learning_rate': 3.6925712770810236e-07, 'epoch': 0.33}\n",
      "{'loss': 1.608, 'grad_norm': 2.2651915550231934, 'learning_rate': 4.153334734761301e-07, 'epoch': 0.37}\n",
      "{'loss': 1.601, 'grad_norm': 2.152513265609741, 'learning_rate': 4.6150215661042645e-07, 'epoch': 0.41}\n",
      "{'loss': 1.5655, 'grad_norm': 2.8852338790893555, 'learning_rate': 5.075785023784542e-07, 'epoch': 0.45}\n",
      "{'loss': 1.4283, 'grad_norm': 5.3558244705200195, 'learning_rate': 5.535625107802134e-07, 'epoch': 0.49}\n",
      "{'loss': 1.3198, 'grad_norm': 8.603870391845703, 'learning_rate': 5.996388565482411e-07, 'epoch': 0.53}\n",
      "{'loss': 1.2777, 'grad_norm': 7.217400074005127, 'learning_rate': 6.458075396825375e-07, 'epoch': 0.57}\n",
      "{'loss': 1.2572, 'grad_norm': 16.148391723632812, 'learning_rate': 6.919762228168338e-07, 'epoch': 0.61}\n",
      "{'loss': 1.2179, 'grad_norm': 8.860563278198242, 'learning_rate': 7.381449059511302e-07, 'epoch': 0.66}\n",
      "{'loss': 1.2147, 'grad_norm': 32.44498825073242, 'learning_rate': 7.84221251719158e-07, 'epoch': 0.7}\n",
      "{'loss': 1.2324, 'grad_norm': 15.872844696044922, 'learning_rate': 8.303899348534543e-07, 'epoch': 0.74}\n",
      "{'loss': 1.1984, 'grad_norm': 13.691914558410645, 'learning_rate': 8.765586179877508e-07, 'epoch': 0.78}\n",
      "{'loss': 1.1965, 'grad_norm': 18.340471267700195, 'learning_rate': 9.226349637557785e-07, 'epoch': 0.82}\n",
      "{'loss': 1.1954, 'grad_norm': 24.776552200317383, 'learning_rate': 9.68803646890075e-07, 'epoch': 0.86}\n",
      "{'loss': 1.2249, 'grad_norm': 21.028457641601562, 'learning_rate': 1.0149723300243713e-06, 'epoch': 0.9}\n",
      "{'loss': 1.1785, 'grad_norm': 10.786514282226562, 'learning_rate': 1.0611410131586676e-06, 'epoch': 0.94}\n",
      "{'loss': 1.1871, 'grad_norm': 14.52995777130127, 'learning_rate': 1.107309696292964e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2e97cfff9d479fad7756233c6a40d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.48500628479080626, 'eval_f1': 0.4752194633764694, 'eval_loss': 1.0283676385879517, 'eval_runtime': 203.1622, 'eval_samples_per_second': 27.412, 'eval_steps_per_second': 9.14, 'epoch': 1.0}\n",
      "{'loss': 1.1663, 'grad_norm': 5.653422832489014, 'learning_rate': 1.1534783794272604e-06, 'epoch': 1.02}\n",
      "{'loss': 1.1563, 'grad_norm': 14.679474830627441, 'learning_rate': 1.1996470625615568e-06, 'epoch': 1.06}\n",
      "{'loss': 1.1571, 'grad_norm': 16.89198875427246, 'learning_rate': 1.2457234083295843e-06, 'epoch': 1.11}\n",
      "{'loss': 1.1636, 'grad_norm': 21.46834373474121, 'learning_rate': 1.2918920914638808e-06, 'epoch': 1.15}\n",
      "{'loss': 1.18, 'grad_norm': 17.93290901184082, 'learning_rate': 1.3380607745981772e-06, 'epoch': 1.19}\n",
      "{'loss': 1.1672, 'grad_norm': 18.56768226623535, 'learning_rate': 1.3842294577324735e-06, 'epoch': 1.23}\n",
      "{'loss': 1.1465, 'grad_norm': 17.17786407470703, 'learning_rate': 1.43039814086677e-06, 'epoch': 1.27}\n",
      "{'loss': 1.1446, 'grad_norm': 29.371938705444336, 'learning_rate': 1.4765668240010663e-06, 'epoch': 1.31}\n",
      "{'loss': 1.1514, 'grad_norm': 14.44872760772705, 'learning_rate': 1.5227355071353626e-06, 'epoch': 1.35}\n",
      "{'loss': 1.1544, 'grad_norm': 12.195289611816406, 'learning_rate': 1.568904190269659e-06, 'epoch': 1.39}\n",
      "{'loss': 1.1318, 'grad_norm': 39.487403869628906, 'learning_rate': 1.614980536037687e-06, 'epoch': 1.43}\n",
      "{'loss': 1.1381, 'grad_norm': 21.45882225036621, 'learning_rate': 1.6610568818057145e-06, 'epoch': 1.47}\n",
      "{'loss': 1.1503, 'grad_norm': 20.607173919677734, 'learning_rate': 1.7072255649400108e-06, 'epoch': 1.52}\n",
      "{'loss': 1.1345, 'grad_norm': 9.572844505310059, 'learning_rate': 1.7533942480743071e-06, 'epoch': 1.56}\n",
      "{'loss': 1.1335, 'grad_norm': 31.30381965637207, 'learning_rate': 1.7995629312086037e-06, 'epoch': 1.6}\n",
      "{'loss': 1.0975, 'grad_norm': 11.411505699157715, 'learning_rate': 1.8456392769766314e-06, 'epoch': 1.64}\n",
      "{'loss': 1.1287, 'grad_norm': 19.305810928344727, 'learning_rate': 1.891807960110928e-06, 'epoch': 1.68}\n",
      "{'loss': 1.1182, 'grad_norm': 22.417705535888672, 'learning_rate': 1.937976643245224e-06, 'epoch': 1.72}\n",
      "{'loss': 1.1282, 'grad_norm': 20.171886444091797, 'learning_rate': 1.9841453263795204e-06, 'epoch': 1.76}\n",
      "{'loss': 1.1221, 'grad_norm': 26.55862045288086, 'learning_rate': 2.0303140095138167e-06, 'epoch': 1.8}\n",
      "{'loss': 1.1272, 'grad_norm': 41.299339294433594, 'learning_rate': 2.076482692648113e-06, 'epoch': 1.84}\n",
      "{'loss': 1.1042, 'grad_norm': 9.568325996398926, 'learning_rate': 2.1226513757824093e-06, 'epoch': 1.88}\n",
      "{'loss': 1.1106, 'grad_norm': 22.134172439575195, 'learning_rate': 2.168820058916706e-06, 'epoch': 1.92}\n",
      "{'loss': 1.0761, 'grad_norm': 19.896013259887695, 'learning_rate': 2.2148964046847336e-06, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6e0588eecb465a8e5e8cbdfb654a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.5403124438857964, 'eval_f1': 0.5345823110550721, 'eval_loss': 0.9354039430618286, 'eval_runtime': 198.6108, 'eval_samples_per_second': 28.04, 'eval_steps_per_second': 9.35, 'epoch': 2.0}\n",
      "{'loss': 1.0902, 'grad_norm': 24.916950225830078, 'learning_rate': 2.26106508781903e-06, 'epoch': 2.01}\n",
      "{'loss': 1.0869, 'grad_norm': 30.588682174682617, 'learning_rate': 2.3072337709533263e-06, 'epoch': 2.05}\n",
      "{'loss': 1.0767, 'grad_norm': 37.92580795288086, 'learning_rate': 2.3534024540876226e-06, 'epoch': 2.09}\n",
      "{'loss': 1.0405, 'grad_norm': 23.347362518310547, 'learning_rate': 2.3994787998556506e-06, 'epoch': 2.13}\n",
      "{'loss': 1.0863, 'grad_norm': 30.37389373779297, 'learning_rate': 2.445647482989947e-06, 'epoch': 2.17}\n",
      "{'loss': 1.0761, 'grad_norm': 32.535125732421875, 'learning_rate': 2.4917238287579745e-06, 'epoch': 2.21}\n",
      "{'loss': 1.0528, 'grad_norm': 42.557430267333984, 'learning_rate': 2.537892511892271e-06, 'epoch': 2.25}\n",
      "{'loss': 1.0385, 'grad_norm': 20.231842041015625, 'learning_rate': 2.584061195026567e-06, 'epoch': 2.29}\n",
      "{'loss': 1.0489, 'grad_norm': 57.25986862182617, 'learning_rate': 2.630229878160864e-06, 'epoch': 2.33}\n",
      "{'loss': 1.0334, 'grad_norm': 24.016407012939453, 'learning_rate': 2.67639856129516e-06, 'epoch': 2.38}\n",
      "{'loss': 1.0482, 'grad_norm': 42.62223434448242, 'learning_rate': 2.7225672444294565e-06, 'epoch': 2.42}\n",
      "{'loss': 1.0452, 'grad_norm': 23.99625587463379, 'learning_rate': 2.7687359275637528e-06, 'epoch': 2.46}\n",
      "{'loss': 1.0211, 'grad_norm': 61.34238052368164, 'learning_rate': 2.8149046106980495e-06, 'epoch': 2.5}\n",
      "{'loss': 1.0227, 'grad_norm': 19.099470138549805, 'learning_rate': 2.860980956466077e-06, 'epoch': 2.54}\n",
      "{'loss': 1.0306, 'grad_norm': 25.077241897583008, 'learning_rate': 2.9071496396003734e-06, 'epoch': 2.58}\n",
      "{'loss': 1.0394, 'grad_norm': 39.585296630859375, 'learning_rate': 2.9533183227346693e-06, 'epoch': 2.62}\n",
      "{'loss': 1.0233, 'grad_norm': 26.069379806518555, 'learning_rate': 2.999487005868966e-06, 'epoch': 2.66}\n",
      "{'loss': 1.0413, 'grad_norm': 25.117305755615234, 'learning_rate': 3.045563351636994e-06, 'epoch': 2.7}\n",
      "{'loss': 1.0404, 'grad_norm': 17.05594825744629, 'learning_rate': 3.09173203477129e-06, 'epoch': 2.74}\n",
      "{'loss': 0.9986, 'grad_norm': 13.825136184692383, 'learning_rate': 3.1379007179055862e-06, 'epoch': 2.78}\n",
      "{'loss': 1.005, 'grad_norm': 30.067707061767578, 'learning_rate': 3.184069401039883e-06, 'epoch': 2.83}\n",
      "{'loss': 1.0157, 'grad_norm': 37.859092712402344, 'learning_rate': 3.230145746807911e-06, 'epoch': 2.87}\n",
      "{'loss': 1.0455, 'grad_norm': 27.656076431274414, 'learning_rate': 3.276314429942207e-06, 'epoch': 2.91}\n",
      "{'loss': 0.9551, 'grad_norm': 66.41449737548828, 'learning_rate': 3.322483113076503e-06, 'epoch': 2.95}\n",
      "{'loss': 0.9886, 'grad_norm': 34.6362190246582, 'learning_rate': 3.3686517962108e-06, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aa1429be0747f48715ea04c4f20a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.609445142754534, 'eval_f1': 0.6084120895467848, 'eval_loss': 0.8753719329833984, 'eval_runtime': 206.0209, 'eval_samples_per_second': 27.031, 'eval_steps_per_second': 9.014, 'epoch': 3.0}\n",
      "{'loss': 0.93, 'grad_norm': 114.12706756591797, 'learning_rate': 3.414635804612559e-06, 'epoch': 3.03}\n",
      "{'loss': 0.9103, 'grad_norm': 11.207834243774414, 'learning_rate': 3.4608044877468555e-06, 'epoch': 3.07}\n",
      "{'loss': 0.9261, 'grad_norm': 26.280357360839844, 'learning_rate': 3.5069731708811514e-06, 'epoch': 3.11}\n",
      "{'loss': 0.9187, 'grad_norm': 12.306319236755371, 'learning_rate': 3.553141854015448e-06, 'epoch': 3.15}\n",
      "{'loss': 0.9034, 'grad_norm': 68.52802276611328, 'learning_rate': 3.5993105371497444e-06, 'epoch': 3.19}\n",
      "{'loss': 0.9301, 'grad_norm': 30.443992614746094, 'learning_rate': 3.6454792202840407e-06, 'epoch': 3.24}\n",
      "{'loss': 0.8885, 'grad_norm': 79.96773529052734, 'learning_rate': 3.6916479034183375e-06, 'epoch': 3.28}\n",
      "{'loss': 0.9779, 'grad_norm': 42.69806671142578, 'learning_rate': 3.7378165865526338e-06, 'epoch': 3.32}\n",
      "{'loss': 0.9249, 'grad_norm': 50.04109573364258, 'learning_rate': 3.7839852696869297e-06, 'epoch': 3.36}\n",
      "{'loss': 0.9247, 'grad_norm': 16.94321060180664, 'learning_rate': 3.830061615454958e-06, 'epoch': 3.4}\n",
      "{'loss': 0.8935, 'grad_norm': 93.2119369506836, 'learning_rate': 3.876230298589254e-06, 'epoch': 3.44}\n",
      "{'loss': 0.9218, 'grad_norm': 10.820450782775879, 'learning_rate': 3.92239898172355e-06, 'epoch': 3.48}\n",
      "{'loss': 0.9117, 'grad_norm': 23.442842483520508, 'learning_rate': 3.968567664857847e-06, 'epoch': 3.52}\n",
      "{'loss': 0.93, 'grad_norm': 18.068859100341797, 'learning_rate': 4.0145516732596054e-06, 'epoch': 3.56}\n",
      "{'loss': 0.8676, 'grad_norm': 20.110742568969727, 'learning_rate': 4.060720356393902e-06, 'epoch': 3.6}\n",
      "{'loss': 0.891, 'grad_norm': 22.85354995727539, 'learning_rate': 4.106889039528199e-06, 'epoch': 3.64}\n",
      "{'loss': 0.9065, 'grad_norm': 31.04128646850586, 'learning_rate': 4.153057722662495e-06, 'epoch': 3.69}\n",
      "{'loss': 0.8554, 'grad_norm': 48.47686767578125, 'learning_rate': 4.199134068430523e-06, 'epoch': 3.73}\n",
      "{'loss': 0.8447, 'grad_norm': 93.11630249023438, 'learning_rate': 4.245210414198551e-06, 'epoch': 3.77}\n",
      "{'loss': 0.8338, 'grad_norm': 43.686065673828125, 'learning_rate': 4.2913790973328475e-06, 'epoch': 3.81}\n",
      "{'loss': 0.9065, 'grad_norm': 26.659387588500977, 'learning_rate': 4.337547780467143e-06, 'epoch': 3.85}\n",
      "{'loss': 0.8466, 'grad_norm': 57.13577651977539, 'learning_rate': 4.383716463601439e-06, 'epoch': 3.89}\n",
      "{'loss': 0.8636, 'grad_norm': 7.696988105773926, 'learning_rate': 4.429885146735736e-06, 'epoch': 3.93}\n",
      "{'loss': 0.8488, 'grad_norm': 28.44072914123535, 'learning_rate': 4.476053829870033e-06, 'epoch': 3.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1574fa14ed514a2385ceeed2363c5a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.6771413180104148, 'eval_f1': 0.6781787765602385, 'eval_loss': 0.8400044441223145, 'eval_runtime': 205.6726, 'eval_samples_per_second': 27.077, 'eval_steps_per_second': 9.029, 'epoch': 4.0}\n",
      "{'loss': 0.8235, 'grad_norm': 114.91957092285156, 'learning_rate': 4.522222513004329e-06, 'epoch': 4.01}\n",
      "{'loss': 0.7423, 'grad_norm': 30.59683609008789, 'learning_rate': 4.5683911961386246e-06, 'epoch': 4.05}\n",
      "{'loss': 0.7446, 'grad_norm': 9.819340705871582, 'learning_rate': 4.6144675419066526e-06, 'epoch': 4.1}\n",
      "{'loss': 0.7536, 'grad_norm': 165.93148803710938, 'learning_rate': 4.660636225040949e-06, 'epoch': 4.14}\n",
      "{'loss': 0.7892, 'grad_norm': 63.92589569091797, 'learning_rate': 4.706804908175245e-06, 'epoch': 4.18}\n",
      "{'loss': 0.7769, 'grad_norm': 5.800497531890869, 'learning_rate': 4.752973591309542e-06, 'epoch': 4.22}\n",
      "{'loss': 0.7976, 'grad_norm': 13.514693260192871, 'learning_rate': 4.799142274443839e-06, 'epoch': 4.26}\n",
      "{'loss': 0.7385, 'grad_norm': 34.404422760009766, 'learning_rate': 4.845218620211866e-06, 'epoch': 4.3}\n",
      "{'loss': 0.7651, 'grad_norm': 23.788591384887695, 'learning_rate': 4.8913873033461625e-06, 'epoch': 4.34}\n",
      "{'loss': 0.7584, 'grad_norm': 21.753231048583984, 'learning_rate': 4.93746364911419e-06, 'epoch': 4.38}\n",
      "{'loss': 0.7631, 'grad_norm': 38.67558288574219, 'learning_rate': 4.9836323322484864e-06, 'epoch': 4.42}\n",
      "{'loss': 0.7795, 'grad_norm': 27.72437286376953, 'learning_rate': 5.029801015382782e-06, 'epoch': 4.46}\n",
      "{'loss': 0.7855, 'grad_norm': 34.288211822509766, 'learning_rate': 5.075969698517079e-06, 'epoch': 4.5}\n",
      "{'loss': 0.7599, 'grad_norm': 109.47402954101562, 'learning_rate': 5.122138381651376e-06, 'epoch': 4.55}\n",
      "{'loss': 0.7989, 'grad_norm': 94.9844970703125, 'learning_rate': 5.168214727419403e-06, 'epoch': 4.59}\n",
      "{'loss': 0.7982, 'grad_norm': 21.695945739746094, 'learning_rate': 5.2143834105537e-06, 'epoch': 4.63}\n",
      "{'loss': 0.7934, 'grad_norm': 53.88724136352539, 'learning_rate': 5.260552093687996e-06, 'epoch': 4.67}\n",
      "{'loss': 0.7582, 'grad_norm': 13.05073070526123, 'learning_rate': 5.306720776822292e-06, 'epoch': 4.71}\n",
      "{'loss': 0.8001, 'grad_norm': 12.62096118927002, 'learning_rate': 5.352889459956589e-06, 'epoch': 4.75}\n",
      "{'loss': 0.7184, 'grad_norm': 9.28813648223877, 'learning_rate': 5.399058143090886e-06, 'epoch': 4.79}\n",
      "{'loss': 0.7295, 'grad_norm': 1.0162678956985474, 'learning_rate': 5.445226826225182e-06, 'epoch': 4.83}\n",
      "{'loss': 0.7804, 'grad_norm': 0.12015388160943985, 'learning_rate': 5.491395509359478e-06, 'epoch': 4.87}\n",
      "{'loss': 0.7338, 'grad_norm': 38.65819549560547, 'learning_rate': 5.5374718551275056e-06, 'epoch': 4.91}\n",
      "{'loss': 0.7648, 'grad_norm': 21.38140106201172, 'learning_rate': 5.5835482008955336e-06, 'epoch': 4.95}\n",
      "{'loss': 0.7698, 'grad_norm': 94.82168579101562, 'learning_rate': 5.62971688402983e-06, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e8196c92f74d679ef7676059bde13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7046148321063027, 'eval_f1': 0.7051720904678767, 'eval_loss': 1.058091402053833, 'eval_runtime': 200.8577, 'eval_samples_per_second': 27.726, 'eval_steps_per_second': 9.245, 'epoch': 5.0}\n",
      "{'loss': 0.6529, 'grad_norm': 194.20571899414062, 'learning_rate': 5.675885567164126e-06, 'epoch': 5.04}\n",
      "{'loss': 0.6368, 'grad_norm': 47.84244155883789, 'learning_rate': 5.722054250298423e-06, 'epoch': 5.08}\n",
      "{'loss': 0.653, 'grad_norm': 72.26734924316406, 'learning_rate': 5.76822293343272e-06, 'epoch': 5.12}\n",
      "{'loss': 0.6327, 'grad_norm': 166.03314208984375, 'learning_rate': 5.814391616567015e-06, 'epoch': 5.16}\n",
      "{'loss': 0.6744, 'grad_norm': 27.890525817871094, 'learning_rate': 5.8605602997013114e-06, 'epoch': 5.2}\n",
      "{'loss': 0.6453, 'grad_norm': 1.888265609741211, 'learning_rate': 5.906728982835607e-06, 'epoch': 5.24}\n",
      "{'loss': 0.6914, 'grad_norm': 12.082417488098145, 'learning_rate': 5.9527129912373674e-06, 'epoch': 5.28}\n",
      "{'loss': 0.6315, 'grad_norm': 20.325645446777344, 'learning_rate': 5.998881674371664e-06, 'epoch': 5.32}\n",
      "{'loss': 0.6267, 'grad_norm': 14.628782272338867, 'learning_rate': 6.045050357505959e-06, 'epoch': 5.36}\n",
      "{'loss': 0.7438, 'grad_norm': 0.06844472140073776, 'learning_rate': 6.091219040640256e-06, 'epoch': 5.41}\n",
      "{'loss': 0.6515, 'grad_norm': 42.87104797363281, 'learning_rate': 6.137295386408283e-06, 'epoch': 5.45}\n",
      "{'loss': 0.6629, 'grad_norm': 78.04370880126953, 'learning_rate': 6.18346406954258e-06, 'epoch': 5.49}\n",
      "{'loss': 0.6868, 'grad_norm': 45.46162796020508, 'learning_rate': 6.229632752676877e-06, 'epoch': 5.53}\n",
      "{'loss': 0.6572, 'grad_norm': 14.030280113220215, 'learning_rate': 6.2758014358111725e-06, 'epoch': 5.57}\n",
      "{'loss': 0.7251, 'grad_norm': 21.50794219970703, 'learning_rate': 6.321970118945469e-06, 'epoch': 5.61}\n",
      "{'loss': 0.6673, 'grad_norm': 6.660283088684082, 'learning_rate': 6.368138802079766e-06, 'epoch': 5.65}\n",
      "{'loss': 0.701, 'grad_norm': 34.469295501708984, 'learning_rate': 6.414307485214062e-06, 'epoch': 5.69}\n",
      "{'loss': 0.7143, 'grad_norm': 3.07405948638916, 'learning_rate': 6.4604761683483586e-06, 'epoch': 5.73}\n",
      "{'loss': 0.706, 'grad_norm': 50.77783966064453, 'learning_rate': 6.5065525141163866e-06, 'epoch': 5.77}\n",
      "{'loss': 0.6627, 'grad_norm': 15.972514152526855, 'learning_rate': 6.5527211972506825e-06, 'epoch': 5.81}\n",
      "{'loss': 0.6817, 'grad_norm': 36.54230499267578, 'learning_rate': 6.598889880384979e-06, 'epoch': 5.86}\n",
      "{'loss': 0.7295, 'grad_norm': 10.917619705200195, 'learning_rate': 6.645058563519276e-06, 'epoch': 5.9}\n",
      "{'loss': 0.6734, 'grad_norm': 15.117615699768066, 'learning_rate': 6.691227246653572e-06, 'epoch': 5.94}\n",
      "{'loss': 0.7344, 'grad_norm': 51.74799728393555, 'learning_rate': 6.7373959297878686e-06, 'epoch': 5.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e114859d21454792900cb96581fab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7232896390734422, 'eval_f1': 0.7221734510471054, 'eval_loss': 1.0246222019195557, 'eval_runtime': 200.9449, 'eval_samples_per_second': 27.714, 'eval_steps_per_second': 9.241, 'epoch': 6.0}\n",
      "{'loss': 0.627, 'grad_norm': 17.28127098083496, 'learning_rate': 6.783564612922164e-06, 'epoch': 6.02}\n",
      "{'loss': 0.6062, 'grad_norm': 13.446760177612305, 'learning_rate': 6.8296409586901924e-06, 'epoch': 6.06}\n",
      "{'loss': 0.5749, 'grad_norm': 198.94032287597656, 'learning_rate': 6.875809641824489e-06, 'epoch': 6.1}\n",
      "{'loss': 0.5605, 'grad_norm': 28.356664657592773, 'learning_rate': 6.921978324958784e-06, 'epoch': 6.14}\n",
      "{'loss': 0.6216, 'grad_norm': 1.864336371421814, 'learning_rate': 6.968147008093081e-06, 'epoch': 6.18}\n",
      "{'loss': 0.5363, 'grad_norm': 19.417322158813477, 'learning_rate': 7.0143156912273786e-06, 'epoch': 6.22}\n",
      "{'loss': 0.6263, 'grad_norm': 74.82840728759766, 'learning_rate': 7.060392036995405e-06, 'epoch': 6.27}\n",
      "{'loss': 0.5782, 'grad_norm': 0.5673591494560242, 'learning_rate': 7.1065607201297024e-06, 'epoch': 6.31}\n",
      "{'loss': 0.6167, 'grad_norm': 14.163994789123535, 'learning_rate': 7.152729403263999e-06, 'epoch': 6.35}\n",
      "{'loss': 0.7118, 'grad_norm': 0.7908238172531128, 'learning_rate': 7.198898086398294e-06, 'epoch': 6.39}\n",
      "{'loss': 0.6629, 'grad_norm': 47.198978424072266, 'learning_rate': 7.245066769532591e-06, 'epoch': 6.43}\n",
      "{'loss': 0.5724, 'grad_norm': 26.453290939331055, 'learning_rate': 7.291235452666887e-06, 'epoch': 6.47}\n",
      "{'loss': 0.6233, 'grad_norm': 64.27200317382812, 'learning_rate': 7.337404135801184e-06, 'epoch': 6.51}\n",
      "{'loss': 0.618, 'grad_norm': 24.155921936035156, 'learning_rate': 7.38357281893548e-06, 'epoch': 6.55}\n",
      "{'loss': 0.6141, 'grad_norm': 261.4867858886719, 'learning_rate': 7.4296491647035075e-06, 'epoch': 6.59}\n",
      "{'loss': 0.661, 'grad_norm': 92.14047241210938, 'learning_rate': 7.475817847837804e-06, 'epoch': 6.63}\n",
      "{'loss': 0.6022, 'grad_norm': 0.896492063999176, 'learning_rate': 7.521894193605832e-06, 'epoch': 6.67}\n",
      "{'loss': 0.6303, 'grad_norm': 127.74901580810547, 'learning_rate': 7.568062876740128e-06, 'epoch': 6.72}\n",
      "{'loss': 0.7033, 'grad_norm': 0.02215038798749447, 'learning_rate': 7.614231559874425e-06, 'epoch': 6.76}\n",
      "{'loss': 0.6148, 'grad_norm': 0.1254713386297226, 'learning_rate': 7.66040024300872e-06, 'epoch': 6.8}\n",
      "{'loss': 0.6882, 'grad_norm': 17.6990909576416, 'learning_rate': 7.706568926143017e-06, 'epoch': 6.84}\n",
      "{'loss': 0.633, 'grad_norm': 0.18686531484127045, 'learning_rate': 7.752737609277313e-06, 'epoch': 6.88}\n",
      "{'loss': 0.6511, 'grad_norm': 172.22525024414062, 'learning_rate': 7.79890629241161e-06, 'epoch': 6.92}\n",
      "{'loss': 0.6517, 'grad_norm': 17.76041603088379, 'learning_rate': 7.844982638179638e-06, 'epoch': 6.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2508ba9798ef44cc96d6f265f4eaffc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.7196983300413, 'eval_f1': 0.7170882920260311, 'eval_loss': 1.6598151922225952, 'eval_runtime': 201.6617, 'eval_samples_per_second': 27.616, 'eval_steps_per_second': 9.208, 'epoch': 7.0}\n",
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "{'train_runtime': 32963.4796, 'train_samples_per_second': 33.337, 'train_steps_per_second': 11.112, 'train_loss': 0.9336256640242236, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe7f7c46130472983b1c282ef41a7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 00:09:57,273] Trial 5 finished with value: 0.7232896390734422 and parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 2.0092610900045777e-05, 'batch_size': 3, 'warmup_ratio': 0.5940475933128249, 'weight_decay': 0.2165300105800973, 'adam_beta1': 0.9336589550502725, 'adam_beta2': 0.9904720666000915, 'adam_epsilon': 5.339974252727158e-07, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.7502244568145089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Current Trial 6 parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 2.4576574011202056e-06, 'batch_size': 3, 'warmup_ratio': 0.07900318797996031, 'weight_decay': 0.11740313596289634, 'adam_beta1': 0.9046532877964253, 'adam_beta2': 0.990803071441722, 'adam_epsilon': 6.153164091684715e-08, 'lr_scheduler_type': 'cosine'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f032a16f44274801b67a60a668cf9f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6078, 'grad_norm': 2.6002676486968994, 'learning_rate': 4.24627216061406e-08, 'epoch': 0.04}\n",
      "{'loss': 1.6078, 'grad_norm': 2.7763030529022217, 'learning_rate': 8.49254432122812e-08, 'epoch': 0.08}\n",
      "{'loss': 1.6089, 'grad_norm': 1.9080065488815308, 'learning_rate': 1.273881648184218e-07, 'epoch': 0.12}\n",
      "{'loss': 1.6016, 'grad_norm': 2.526806354522705, 'learning_rate': 1.697659609813501e-07, 'epoch': 0.16}\n",
      "{'loss': 1.5785, 'grad_norm': 2.5043411254882812, 'learning_rate': 2.1214375714427845e-07, 'epoch': 0.2}\n",
      "{'loss': 1.5497, 'grad_norm': 4.560710430145264, 'learning_rate': 2.5460647875041906e-07, 'epoch': 0.25}\n",
      "{'loss': 1.5061, 'grad_norm': 2.4298624992370605, 'learning_rate': 2.9706920035655964e-07, 'epoch': 0.29}\n",
      "{'loss': 1.4399, 'grad_norm': 8.192427635192871, 'learning_rate': 3.3944699651948795e-07, 'epoch': 0.33}\n",
      "{'loss': 1.3794, 'grad_norm': 6.8591389656066895, 'learning_rate': 3.8190971812562853e-07, 'epoch': 0.37}\n",
      "{'loss': 1.3241, 'grad_norm': 20.71944236755371, 'learning_rate': 4.243724397317691e-07, 'epoch': 0.41}\n",
      "{'loss': 1.2866, 'grad_norm': 6.473512649536133, 'learning_rate': 4.667502358946975e-07, 'epoch': 0.45}\n",
      "{'loss': 1.2696, 'grad_norm': 15.09011459350586, 'learning_rate': 5.092129575008381e-07, 'epoch': 0.49}\n",
      "{'loss': 1.2463, 'grad_norm': 29.2030086517334, 'learning_rate': 5.516756791069787e-07, 'epoch': 0.53}\n",
      "{'loss': 1.2503, 'grad_norm': 11.240111351013184, 'learning_rate': 5.94053475269907e-07, 'epoch': 0.57}\n",
      "{'loss': 1.2417, 'grad_norm': 15.0079927444458, 'learning_rate': 6.365161968760476e-07, 'epoch': 0.61}\n",
      "{'loss': 1.202, 'grad_norm': 9.219319343566895, 'learning_rate': 6.789789184821882e-07, 'epoch': 0.66}\n",
      "{'loss': 1.2036, 'grad_norm': 26.82164764404297, 'learning_rate': 7.214416400883288e-07, 'epoch': 0.7}\n",
      "{'loss': 1.2217, 'grad_norm': 14.941695213317871, 'learning_rate': 7.639043616944694e-07, 'epoch': 0.74}\n",
      "{'loss': 1.2141, 'grad_norm': 14.368852615356445, 'learning_rate': 8.062821578573978e-07, 'epoch': 0.78}\n",
      "{'loss': 1.2091, 'grad_norm': 19.17595100402832, 'learning_rate': 8.487448794635382e-07, 'epoch': 0.82}\n",
      "{'loss': 1.1945, 'grad_norm': 17.64557456970215, 'learning_rate': 8.912076010696789e-07, 'epoch': 0.86}\n",
      "{'loss': 1.2254, 'grad_norm': 17.043807983398438, 'learning_rate': 9.336703226758194e-07, 'epoch': 0.9}\n",
      "{'loss': 1.1897, 'grad_norm': 15.080906867980957, 'learning_rate': 9.7613304428196e-07, 'epoch': 0.94}\n",
      "{'loss': 1.1741, 'grad_norm': 20.951213836669922, 'learning_rate': 1.0185957658881006e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a9da5fbb1b4fdba0130be0c6ac7068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.49308673011312626, 'eval_f1': 0.48962724894363163, 'eval_loss': 1.0431489944458008, 'eval_runtime': 206.8759, 'eval_samples_per_second': 26.92, 'eval_steps_per_second': 8.976, 'epoch': 1.0}\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "{'train_runtime': 4775.0252, 'train_samples_per_second': 230.135, 'train_steps_per_second': 76.712, 'train_loss': 1.3444546311337082, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60ced3c23f44b6399bf5bbc8656dccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 01:32:56,105] Trial 6 finished with value: 0.49308673011312626 and parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 2.4576574011202056e-06, 'batch_size': 3, 'warmup_ratio': 0.07900318797996031, 'weight_decay': 0.11740313596289634, 'adam_beta1': 0.9046532877964253, 'adam_beta2': 0.990803071441722, 'adam_epsilon': 6.153164091684715e-08, 'lr_scheduler_type': 'cosine'}. Best is trial 0 with value: 0.7502244568145089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "Current Trial 7 parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.6467178725088624e-07, 'batch_size': 3, 'warmup_ratio': 0.6518719890876207, 'weight_decay': 0.010273108046471219, 'adam_beta1': 0.9129492559268905, 'adam_beta2': 0.9901934455902108, 'adam_epsilon': 7.518451468450438e-07, 'lr_scheduler_type': 'cosine_with_restarts'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf07f8f334947f39d9938ca031381e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-22 01:35:16,958] Trial 7 failed with parameters: {'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.6467178725088624e-07, 'batch_size': 3, 'warmup_ratio': 0.6518719890876207, 'weight_decay': 0.010273108046471219, 'adam_beta1': 0.9129492559268905, 'adam_beta2': 0.9901934455902108, 'adam_epsilon': 7.518451468450438e-07, 'lr_scheduler_type': 'cosine_with_restarts'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\OEM\\AppData\\Local\\Temp\\ipykernel_22244\\84796339.py\", line 59, in objective\n",
      "    trainer.train()\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py\", line 1938, in train\n",
      "    return inner_training_loop(\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py\", line 2279, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py\", line 3349, in training_step\n",
      "    self.accelerator.backward(loss, **kwargs)\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py\", line 2192, in backward\n",
      "    self.scaler.scale(loss).backward(**kwargs)\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\torch\\_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\torch\\autograd\\graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-22 01:35:16,961] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m study\u001b[38;5;241m.\u001b[39menqueue_trial({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicrosoft/deberta-v3-base\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0052258285035737e-05\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarmup_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.04149176551014211\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.006685281279171756\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam_beta1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.9429922176765829\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam_beta2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.9918592948813898\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam_epsilon\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m8.867767549079712e-08\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_scheduler_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine_with_restarts\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#study.enqueue_trial({'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.5807103066634623e-05, 'batch_size': 4, 'warmup_ratio': 0.5994150649377659, 'weight_decay': 0.12506835879573128, 'adam_beta1': 0.8136227307274486, 'adam_beta2': 0.9924116710027883, 'adam_epsilon': 1.9858068243318367e-07, 'lr_scheduler_type': 'cosine_with_restarts'})\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[13], line 59\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     48\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     49\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_init(model_name),\n\u001b[0;32m     50\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[AdvancedEarlyStoppingCallback(metric_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     62\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2285\u001b[0m ):\n\u001b[0;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py:3349\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3347\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:2192\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2193\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a study object and optimize the objective\n",
    "global_run_name=\"Optuna-1\"\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.enqueue_trial({'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.0052258285035737e-05, 'batch_size': 3, 'warmup_ratio': 0.04149176551014211, 'weight_decay': 0.006685281279171756, 'adam_beta1': 0.9429922176765829, 'adam_beta2': 0.9918592948813898, 'adam_epsilon': 8.867767549079712e-08, 'lr_scheduler_type': 'cosine_with_restarts'})\n",
    "#study.enqueue_trial({'model_name': 'microsoft/deberta-v3-base', 'learning_rate': 1.5807103066634623e-05, 'batch_size': 4, 'warmup_ratio': 0.5994150649377659, 'weight_decay': 0.12506835879573128, 'adam_beta1': 0.8136227307274486, 'adam_beta2': 0.9924116710027883, 'adam_epsilon': 1.9858068243318367e-07, 'lr_scheduler_type': 'cosine_with_restarts'})\n",
    "study.optimize(objective, n_trials=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4db3c9",
   "metadata": {},
   "source": [
    "## 4.3 Optuna Hyperparameters Tuning 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9169a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 01:57:26,347] A new study created in memory with name: no-name-198a630a-9e5c-4ede-ae18-36aabe3fac1a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Trial 0 parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.15718330934471478, 'learning_rate': 1.5807103066634623e-05, 'batch_size': 4, 'warmup_ratio': 0.5994150649377659, 'weight_decay': 0.12506835879573128, 'adam_beta1': 0.8136227307274486, 'adam_beta2': 0.9924116710027883, 'adam_epsilon': 1.9858068243318367e-07, 'lr_scheduler_type': 'cosine_with_restarts'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForMultipleChoice were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135ca6e0a7d442a8bbd5136dac6452ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6088, 'grad_norm': 0.9182241559028625, 'learning_rate': 4.780025580617451e-08, 'epoch': 0.05}\n",
      "{'loss': 1.6088, 'grad_norm': 0.7863313555717468, 'learning_rate': 9.569649606175901e-08, 'epoch': 0.11}\n",
      "{'loss': 1.6093, 'grad_norm': 0.7911553978919983, 'learning_rate': 1.4368872076675347e-07, 'epoch': 0.16}\n",
      "{'loss': 1.6085, 'grad_norm': 0.8689716458320618, 'learning_rate': 1.91488976572928e-07, 'epoch': 0.22}\n",
      "{'loss': 1.6076, 'grad_norm': 0.8607678413391113, 'learning_rate': 2.3948120127792246e-07, 'epoch': 0.27}\n",
      "{'loss': 1.6065, 'grad_norm': 1.0950431823730469, 'learning_rate': 2.8737744153350694e-07, 'epoch': 0.33}\n",
      "{'loss': 1.6024, 'grad_norm': 1.1426678895950317, 'learning_rate': 3.3536966623850147e-07, 'epoch': 0.38}\n",
      "{'loss': 1.5868, 'grad_norm': 1.5567299127578735, 'learning_rate': 3.8336189094349596e-07, 'epoch': 0.44}\n",
      "{'loss': 1.5336, 'grad_norm': 2.8619110584259033, 'learning_rate': 4.3135411564849044e-07, 'epoch': 0.49}\n",
      "{'loss': 1.4498, 'grad_norm': 3.4570772647857666, 'learning_rate': 4.792503559040749e-07, 'epoch': 0.55}\n",
      "{'loss': 1.3822, 'grad_norm': 4.822655200958252, 'learning_rate': 5.270506117102494e-07, 'epoch': 0.6}\n",
      "{'loss': 1.3307, 'grad_norm': 9.937758445739746, 'learning_rate': 5.750428364152439e-07, 'epoch': 0.66}\n",
      "{'loss': 1.3258, 'grad_norm': 14.819893836975098, 'learning_rate': 6.230350611202384e-07, 'epoch': 0.71}\n",
      "{'loss': 1.3088, 'grad_norm': 37.391571044921875, 'learning_rate': 6.710272858252329e-07, 'epoch': 0.76}\n",
      "{'loss': 1.2735, 'grad_norm': 16.22966194152832, 'learning_rate': 7.190195105302274e-07, 'epoch': 0.82}\n",
      "{'loss': 1.2904, 'grad_norm': 15.184688568115234, 'learning_rate': 7.670117352352218e-07, 'epoch': 0.87}\n",
      "{'loss': 1.267, 'grad_norm': 12.10547924041748, 'learning_rate': 8.149079754908063e-07, 'epoch': 0.93}\n",
      "{'loss': 1.2554, 'grad_norm': 7.877290725708008, 'learning_rate': 8.628042157463908e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b979213031034d029f5fdb1431c24689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.45789190159813253, 'eval_f1': 0.4441435889737021, 'eval_loss': 1.154205560684204, 'eval_runtime': 130.2404, 'eval_samples_per_second': 42.759, 'eval_steps_per_second': 10.696, 'epoch': 1.0}\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "{'train_runtime': 2960.9734, 'train_samples_per_second': 371.128, 'train_steps_per_second': 92.787, 'train_loss': 1.4549762686675072, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f32010e9d941788cab35b01cf2953a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 02:48:58,638] Trial 0 finished with value: 0.45789190159813253 and parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.15718330934471478, 'learning_rate': 1.5807103066634623e-05, 'batch_size': 4, 'warmup_ratio': 0.5994150649377659, 'weight_decay': 0.12506835879573128, 'adam_beta1': 0.8136227307274486, 'adam_beta2': 0.9924116710027883, 'adam_epsilon': 1.9858068243318367e-07, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.45789190159813253.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "Current Trial 1 parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.3046487955829154, 'learning_rate': 4.1206992440781206e-07, 'batch_size': 3, 'warmup_ratio': 0.07116169962743613, 'weight_decay': 0.2388626303853753, 'adam_beta1': 0.8422162512825583, 'adam_beta2': 0.9904831834704457, 'adam_epsilon': 5.201468169219309e-07, 'lr_scheduler_type': 'cosine_with_restarts'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForMultipleChoice were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f601bfb1ec43e38bd0e05d760dbc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6105, 'grad_norm': 1.0038748979568481, 'learning_rate': 7.888245378428597e-09, 'epoch': 0.04}\n",
      "{'loss': 1.6097, 'grad_norm': 0.9802391529083252, 'learning_rate': 1.5776490756857193e-08, 'epoch': 0.08}\n",
      "{'loss': 1.6096, 'grad_norm': 0.9342759847640991, 'learning_rate': 2.364892802831499e-08, 'epoch': 0.12}\n",
      "{'loss': 1.6092, 'grad_norm': 0.9232449531555176, 'learning_rate': 3.155298151371439e-08, 'epoch': 0.16}\n",
      "{'loss': 1.6099, 'grad_norm': 0.9416474103927612, 'learning_rate': 3.945703499911378e-08, 'epoch': 0.2}\n",
      "{'loss': 1.6095, 'grad_norm': 0.9696550369262695, 'learning_rate': 4.734528037754238e-08, 'epoch': 0.25}\n",
      "{'loss': 1.6097, 'grad_norm': 1.3210350275039673, 'learning_rate': 5.524933386294177e-08, 'epoch': 0.29}\n",
      "{'loss': 1.6095, 'grad_norm': 0.9429779648780823, 'learning_rate': 6.315338734834116e-08, 'epoch': 0.33}\n",
      "{'loss': 1.6089, 'grad_norm': 1.0847434997558594, 'learning_rate': 7.105744083374056e-08, 'epoch': 0.37}\n",
      "{'loss': 1.6081, 'grad_norm': 1.0135345458984375, 'learning_rate': 7.896149431913996e-08, 'epoch': 0.41}\n",
      "{'loss': 1.609, 'grad_norm': 0.9849110841751099, 'learning_rate': 8.686554780453936e-08, 'epoch': 0.45}\n",
      "{'loss': 1.6082, 'grad_norm': 1.1165719032287598, 'learning_rate': 9.476960128993875e-08, 'epoch': 0.49}\n",
      "{'loss': 1.6083, 'grad_norm': 1.0244745016098022, 'learning_rate': 1.0267365477533815e-07, 'epoch': 0.53}\n",
      "{'loss': 1.608, 'grad_norm': 1.0121873617172241, 'learning_rate': 1.1057770826073753e-07, 'epoch': 0.57}\n",
      "{'loss': 1.6074, 'grad_norm': 1.053575873374939, 'learning_rate': 1.1846595363916614e-07, 'epoch': 0.61}\n",
      "{'loss': 1.6058, 'grad_norm': 5.690029144287109, 'learning_rate': 1.2635419901759473e-07, 'epoch': 0.66}\n",
      "{'loss': 1.6059, 'grad_norm': 1.0543270111083984, 'learning_rate': 1.3425825250299413e-07, 'epoch': 0.7}\n",
      "{'loss': 1.605, 'grad_norm': 1.243895411491394, 'learning_rate': 1.4216230598839353e-07, 'epoch': 0.74}\n",
      "{'loss': 1.6024, 'grad_norm': 1.2252775430679321, 'learning_rate': 1.5006635947379293e-07, 'epoch': 0.78}\n",
      "{'loss': 1.5998, 'grad_norm': 1.137698769569397, 'learning_rate': 1.579704129591923e-07, 'epoch': 0.82}\n",
      "{'loss': 1.5939, 'grad_norm': 1.5133697986602783, 'learning_rate': 1.658744664445917e-07, 'epoch': 0.86}\n",
      "{'loss': 1.5872, 'grad_norm': 1.272009015083313, 'learning_rate': 1.737785199299911e-07, 'epoch': 0.9}\n",
      "{'loss': 1.5707, 'grad_norm': 1.8961106538772583, 'learning_rate': 1.816825734153905e-07, 'epoch': 0.94}\n",
      "{'loss': 1.5509, 'grad_norm': 2.1738815307617188, 'learning_rate': 1.895708187938191e-07, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989396a4198e42d2aa7bdf1bef4846d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.4410127491470641, 'eval_f1': 0.43217578765164366, 'eval_loss': 1.4569653272628784, 'eval_runtime': 129.4868, 'eval_samples_per_second': 43.008, 'eval_steps_per_second': 14.341, 'epoch': 1.0}\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "{'train_runtime': 2948.5397, 'train_samples_per_second': 372.693, 'train_steps_per_second': 124.231, 'train_loss': 1.6010893125791807, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94105c42ddd7453b8ffbe8577dd43199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 03:40:18,641] Trial 1 finished with value: 0.4410127491470641 and parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.3046487955829154, 'learning_rate': 4.1206992440781206e-07, 'batch_size': 3, 'warmup_ratio': 0.07116169962743613, 'weight_decay': 0.2388626303853753, 'adam_beta1': 0.8422162512825583, 'adam_beta2': 0.9904831834704457, 'adam_epsilon': 5.201468169219309e-07, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.45789190159813253.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "Current Trial 2 parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.10926740728558144, 'learning_rate': 1.335608479306097e-05, 'batch_size': 3, 'warmup_ratio': 0.41012687080315513, 'weight_decay': 0.09479782297028039, 'adam_beta1': 0.912797523704336, 'adam_beta2': 0.997103226208837, 'adam_epsilon': 7.229757891985637e-07, 'lr_scheduler_type': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForMultipleChoice were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ad89151cea450b88a3e22acdf99d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6105, 'grad_norm': 1.0041431188583374, 'learning_rate': 4.418540998569728e-08, 'epoch': 0.04}\n",
      "{'loss': 1.6095, 'grad_norm': 0.9794089198112488, 'learning_rate': 8.863753270772673e-08, 'epoch': 0.08}\n",
      "{'loss': 1.6093, 'grad_norm': 0.9342834949493408, 'learning_rate': 1.330896554297562e-07, 'epoch': 0.12}\n",
      "{'loss': 1.6086, 'grad_norm': 0.9255183935165405, 'learning_rate': 1.774528739063416e-07, 'epoch': 0.16}\n",
      "{'loss': 1.609, 'grad_norm': 0.9468817710876465, 'learning_rate': 2.2190499662837103e-07, 'epoch': 0.2}\n",
      "{'loss': 1.6078, 'grad_norm': 0.9842406511306763, 'learning_rate': 2.6626821510495643e-07, 'epoch': 0.25}\n",
      "{'loss': 1.6068, 'grad_norm': 1.0521067380905151, 'learning_rate': 3.1072033782698587e-07, 'epoch': 0.29}\n",
      "{'loss': 1.6038, 'grad_norm': 1.0336287021636963, 'learning_rate': 3.5517246054901536e-07, 'epoch': 0.33}\n",
      "{'loss': 1.5938, 'grad_norm': 1.386725902557373, 'learning_rate': 3.996245832710448e-07, 'epoch': 0.37}\n",
      "{'loss': 1.5667, 'grad_norm': 1.9762277603149414, 'learning_rate': 4.440767059930743e-07, 'epoch': 0.41}\n",
      "{'loss': 1.5031, 'grad_norm': 4.502912521362305, 'learning_rate': 4.882621159787716e-07, 'epoch': 0.45}\n",
      "{'loss': 1.4316, 'grad_norm': 3.5446276664733887, 'learning_rate': 5.327142387008009e-07, 'epoch': 0.49}\n",
      "{'loss': 1.3792, 'grad_norm': 8.139463424682617, 'learning_rate': 5.771663614228305e-07, 'epoch': 0.53}\n",
      "{'loss': 1.3415, 'grad_norm': 1.9827455282211304, 'learning_rate': 6.215295798994158e-07, 'epoch': 0.57}\n",
      "{'loss': 1.3302, 'grad_norm': 19.97446060180664, 'learning_rate': 6.658927983760013e-07, 'epoch': 0.61}\n",
      "{'loss': 1.3296, 'grad_norm': 30.350744247436523, 'learning_rate': 7.103449210980307e-07, 'epoch': 0.66}\n",
      "{'loss': 1.3047, 'grad_norm': 35.56308364868164, 'learning_rate': 7.547970438200602e-07, 'epoch': 0.7}\n",
      "{'loss': 1.3144, 'grad_norm': 16.744962692260742, 'learning_rate': 7.992491665420896e-07, 'epoch': 0.74}\n",
      "{'loss': 1.2778, 'grad_norm': 16.832265853881836, 'learning_rate': 8.436123850186751e-07, 'epoch': 0.78}\n",
      "{'loss': 1.262, 'grad_norm': 17.182348251342773, 'learning_rate': 8.880645077407045e-07, 'epoch': 0.82}\n",
      "{'loss': 1.2796, 'grad_norm': 5.064531326293945, 'learning_rate': 9.325166304627339e-07, 'epoch': 0.86}\n",
      "{'loss': 1.268, 'grad_norm': 21.449968338012695, 'learning_rate': 9.769687531847633e-07, 'epoch': 0.9}\n",
      "{'loss': 1.2336, 'grad_norm': 10.136995315551758, 'learning_rate': 1.021420875906793e-06, 'epoch': 0.94}\n",
      "{'loss': 1.234, 'grad_norm': 12.402498245239258, 'learning_rate': 1.0658729986288224e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d91ab4559de41638b41882819f97d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.46004668701741785, 'eval_f1': 0.4511414731237447, 'eval_loss': 1.158411979675293, 'eval_runtime': 129.244, 'eval_samples_per_second': 43.089, 'eval_steps_per_second': 14.368, 'epoch': 1.0}\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "{'train_runtime': 2948.6868, 'train_samples_per_second': 372.674, 'train_steps_per_second': 124.225, 'train_loss': 1.434618428298238, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334eb3908e5b402fa327d414fc6e617c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 04:31:38,277] Trial 2 finished with value: 0.46004668701741785 and parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.10926740728558144, 'learning_rate': 1.335608479306097e-05, 'batch_size': 3, 'warmup_ratio': 0.41012687080315513, 'weight_decay': 0.09479782297028039, 'adam_beta1': 0.912797523704336, 'adam_beta2': 0.997103226208837, 'adam_epsilon': 7.229757891985637e-07, 'lr_scheduler_type': 'linear'}. Best is trial 2 with value: 0.46004668701741785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "Current Trial 3 parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.1816376875451311, 'learning_rate': 5.4982191466617046e-05, 'batch_size': 4, 'warmup_ratio': 0.6229699420810516, 'weight_decay': 0.07934363728473695, 'adam_beta1': 0.9386008693968517, 'adam_beta2': 0.9935052156642877, 'adam_epsilon': 6.932517927990338e-07, 'lr_scheduler_type': 'cosine'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForMultipleChoice were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6282742a40745f7a046d670480aa762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6095, 'grad_norm': 0.8916115760803223, 'learning_rate': 1.5997856533770726e-07, 'epoch': 0.05}\n",
      "{'loss': 1.6094, 'grad_norm': 0.935311496257782, 'learning_rate': 3.2027837277448625e-07, 'epoch': 0.11}\n",
      "{'loss': 1.6084, 'grad_norm': 0.7695035338401794, 'learning_rate': 4.808994223103369e-07, 'epoch': 0.16}\n",
      "{'loss': 1.6056, 'grad_norm': 1.04118013381958, 'learning_rate': 6.415204718461876e-07, 'epoch': 0.22}\n",
      "{'loss': 1.5815, 'grad_norm': 3.112593173980713, 'learning_rate': 8.021415213820383e-07, 'epoch': 0.27}\n",
      "{'loss': 1.4552, 'grad_norm': 16.392295837402344, 'learning_rate': 9.62441328818817e-07, 'epoch': 0.33}\n",
      "{'loss': 1.3405, 'grad_norm': 22.638620376586914, 'learning_rate': 1.1224198941565245e-06, 'epoch': 0.38}\n",
      "{'loss': 1.2959, 'grad_norm': 16.598974227905273, 'learning_rate': 1.2823984594942319e-06, 'epoch': 0.44}\n",
      "{'loss': 1.2856, 'grad_norm': 16.50101089477539, 'learning_rate': 1.4430195090300825e-06, 'epoch': 0.49}\n",
      "{'loss': 1.288, 'grad_norm': 3.342400312423706, 'learning_rate': 1.6033193164668614e-06, 'epoch': 0.55}\n",
      "{'loss': 1.2777, 'grad_norm': 55.011451721191406, 'learning_rate': 1.7636191239036405e-06, 'epoch': 0.6}\n",
      "{'loss': 1.2367, 'grad_norm': 11.459199905395508, 'learning_rate': 1.924240173439491e-06, 'epoch': 0.66}\n",
      "{'loss': 1.2335, 'grad_norm': 7.066983222961426, 'learning_rate': 2.084861222975342e-06, 'epoch': 0.71}\n",
      "{'loss': 1.2325, 'grad_norm': 29.7535343170166, 'learning_rate': 2.2454822725111924e-06, 'epoch': 0.76}\n",
      "{'loss': 1.2092, 'grad_norm': 23.53926658630371, 'learning_rate': 2.4061033220470435e-06, 'epoch': 0.82}\n",
      "{'loss': 1.2223, 'grad_norm': 11.238018989562988, 'learning_rate': 2.566724371582894e-06, 'epoch': 0.87}\n",
      "{'loss': 1.1995, 'grad_norm': 14.918429374694824, 'learning_rate': 2.7273454211187447e-06, 'epoch': 0.93}\n",
      "{'loss': 1.2015, 'grad_norm': 10.35622501373291, 'learning_rate': 2.88700274435738e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df45993fe7040a999cb74836513b29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.4720775722750943, 'eval_f1': 0.46856230684954503, 'eval_loss': 1.133382797241211, 'eval_runtime': 129.7892, 'eval_samples_per_second': 42.908, 'eval_steps_per_second': 10.733, 'epoch': 1.0}\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "{'train_runtime': 2899.806, 'train_samples_per_second': 378.956, 'train_steps_per_second': 94.744, 'train_loss': 1.357816904021757, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6470e54e4548b890c5732f4ea9b528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 05:22:09,212] Trial 3 finished with value: 0.4720775722750943 and parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.1816376875451311, 'learning_rate': 5.4982191466617046e-05, 'batch_size': 4, 'warmup_ratio': 0.6229699420810516, 'weight_decay': 0.07934363728473695, 'adam_beta1': 0.9386008693968517, 'adam_beta2': 0.9935052156642877, 'adam_epsilon': 6.932517927990338e-07, 'lr_scheduler_type': 'cosine'}. Best is trial 3 with value: 0.4720775722750943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "Current Trial 4 parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.2500228054734358, 'learning_rate': 6.331007353356651e-05, 'batch_size': 3, 'warmup_ratio': 0.31837920111611373, 'weight_decay': 0.09971031186766507, 'adam_beta1': 0.8682929292594384, 'adam_beta2': 0.9909672212836867, 'adam_epsilon': 5.424397228138408e-07, 'lr_scheduler_type': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForMultipleChoice were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2df9610c9a459f8c165bf5513b07f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6105, 'grad_norm': 1.003128170967102, 'learning_rate': 2.703447572066927e-07, 'epoch': 0.04}\n",
      "{'loss': 1.6088, 'grad_norm': 0.9811621904373169, 'learning_rate': 5.417752363298781e-07, 'epoch': 0.08}\n",
      "{'loss': 1.6068, 'grad_norm': 1.012223720550537, 'learning_rate': 8.132057154530636e-07, 'epoch': 0.12}\n",
      "{'loss': 1.5915, 'grad_norm': 1.8195114135742188, 'learning_rate': 1.0840933336180026e-06, 'epoch': 0.16}\n",
      "{'loss': 1.472, 'grad_norm': 4.724691390991211, 'learning_rate': 1.3544380908246952e-06, 'epoch': 0.2}\n",
      "{'loss': 1.3579, 'grad_norm': 15.955487251281738, 'learning_rate': 1.6258685699478809e-06, 'epoch': 0.25}\n",
      "{'loss': 1.3038, 'grad_norm': 37.59272384643555, 'learning_rate': 1.8972990490710663e-06, 'epoch': 0.29}\n",
      "{'loss': 1.2731, 'grad_norm': 18.960540771484375, 'learning_rate': 2.167643806277759e-06, 'epoch': 0.33}\n",
      "{'loss': 1.2412, 'grad_norm': 6.070656776428223, 'learning_rate': 2.439074285400944e-06, 'epoch': 0.37}\n",
      "{'loss': 1.2635, 'grad_norm': 17.87575912475586, 'learning_rate': 2.71050476452413e-06, 'epoch': 0.41}\n",
      "{'loss': 1.2377, 'grad_norm': 10.940373420715332, 'learning_rate': 2.981392382689069e-06, 'epoch': 0.45}\n",
      "{'loss': 1.2378, 'grad_norm': 18.635204315185547, 'learning_rate': 3.2528228618122544e-06, 'epoch': 0.49}\n",
      "{'loss': 1.2384, 'grad_norm': 5.704532146453857, 'learning_rate': 3.52425334093544e-06, 'epoch': 0.53}\n",
      "{'loss': 1.2208, 'grad_norm': 20.00847625732422, 'learning_rate': 3.7956838200586254e-06, 'epoch': 0.57}\n",
      "{'loss': 1.2082, 'grad_norm': 35.61050033569336, 'learning_rate': 4.06711429918181e-06, 'epoch': 0.61}\n",
      "{'loss': 1.1778, 'grad_norm': 8.443663597106934, 'learning_rate': 4.338544778304996e-06, 'epoch': 0.66}\n",
      "{'loss': 1.1779, 'grad_norm': 22.02908706665039, 'learning_rate': 4.609975257428182e-06, 'epoch': 0.7}\n",
      "{'loss': 1.2114, 'grad_norm': 9.237483024597168, 'learning_rate': 4.881405736551367e-06, 'epoch': 0.74}\n",
      "{'loss': 1.1791, 'grad_norm': 12.181902885437012, 'learning_rate': 5.152836215674552e-06, 'epoch': 0.78}\n",
      "{'loss': 1.1844, 'grad_norm': 14.46401309967041, 'learning_rate': 5.423723833839492e-06, 'epoch': 0.82}\n",
      "{'loss': 1.1798, 'grad_norm': 193.4146270751953, 'learning_rate': 5.69461145200443e-06, 'epoch': 0.86}\n",
      "{'loss': 1.1902, 'grad_norm': 21.213825225830078, 'learning_rate': 5.9660419311276156e-06, 'epoch': 0.9}\n",
      "{'loss': 1.1694, 'grad_norm': 10.657881736755371, 'learning_rate': 6.237472410250802e-06, 'epoch': 0.94}\n",
      "{'loss': 1.1625, 'grad_norm': 14.470998764038086, 'learning_rate': 6.508902889373987e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46a1f1875bd4dfd970f7a58bdb10f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.51212066798348, 'eval_f1': 0.5008762224153099, 'eval_loss': 1.0327595472335815, 'eval_runtime': 129.2988, 'eval_samples_per_second': 43.071, 'eval_steps_per_second': 14.362, 'epoch': 1.0}\n",
      "{'loss': 1.1207, 'grad_norm': 25.40252113342285, 'learning_rate': 6.780333368497172e-06, 'epoch': 1.02}\n",
      "{'loss': 1.1143, 'grad_norm': 19.99736213684082, 'learning_rate': 7.051220986662111e-06, 'epoch': 1.06}\n",
      "{'loss': 1.1162, 'grad_norm': 15.271824836730957, 'learning_rate': 7.322108604827051e-06, 'epoch': 1.11}\n",
      "{'loss': 1.1192, 'grad_norm': 30.091594696044922, 'learning_rate': 7.593539083950236e-06, 'epoch': 1.15}\n",
      "{'loss': 1.1263, 'grad_norm': 20.144153594970703, 'learning_rate': 7.864969563073422e-06, 'epoch': 1.19}\n",
      "{'loss': 1.0935, 'grad_norm': 9.870036125183105, 'learning_rate': 8.136400042196607e-06, 'epoch': 1.23}\n",
      "{'loss': 1.1304, 'grad_norm': 19.627023696899414, 'learning_rate': 8.407830521319792e-06, 'epoch': 1.27}\n",
      "{'loss': 1.1352, 'grad_norm': 30.71637535095215, 'learning_rate': 8.679261000442978e-06, 'epoch': 1.31}\n",
      "{'loss': 1.115, 'grad_norm': 5.224144458770752, 'learning_rate': 8.950691479566163e-06, 'epoch': 1.35}\n",
      "{'loss': 1.1172, 'grad_norm': 22.929309844970703, 'learning_rate': 9.222121958689349e-06, 'epoch': 1.39}\n",
      "{'loss': 1.0987, 'grad_norm': 84.35053253173828, 'learning_rate': 9.493009576854289e-06, 'epoch': 1.43}\n",
      "{'loss': 1.1049, 'grad_norm': 35.65603256225586, 'learning_rate': 9.764440055977474e-06, 'epoch': 1.47}\n",
      "{'loss': 1.1362, 'grad_norm': 17.36473274230957, 'learning_rate': 1.0035870535100658e-05, 'epoch': 1.52}\n",
      "{'loss': 1.1173, 'grad_norm': 7.902273178100586, 'learning_rate': 1.0307301014223845e-05, 'epoch': 1.56}\n",
      "{'loss': 1.0962, 'grad_norm': 13.83945369720459, 'learning_rate': 1.057873149334703e-05, 'epoch': 1.6}\n",
      "{'loss': 1.068, 'grad_norm': 13.668889999389648, 'learning_rate': 1.0850161972470216e-05, 'epoch': 1.64}\n",
      "{'loss': 1.1079, 'grad_norm': 23.647907257080078, 'learning_rate': 1.11215924515934e-05, 'epoch': 1.68}\n",
      "{'loss': 1.0831, 'grad_norm': 12.186593055725098, 'learning_rate': 1.1393022930716586e-05, 'epoch': 1.72}\n",
      "{'loss': 1.0707, 'grad_norm': 23.760482788085938, 'learning_rate': 1.1664453409839773e-05, 'epoch': 1.76}\n",
      "{'loss': 1.0658, 'grad_norm': 11.171010971069336, 'learning_rate': 1.1935883888962956e-05, 'epoch': 1.8}\n",
      "{'loss': 1.0854, 'grad_norm': 12.513233184814453, 'learning_rate': 1.2207314368086142e-05, 'epoch': 1.84}\n",
      "{'loss': 1.0491, 'grad_norm': 4.132542610168457, 'learning_rate': 1.2478744847209328e-05, 'epoch': 1.88}\n",
      "{'loss': 1.0701, 'grad_norm': 11.339996337890625, 'learning_rate': 1.2750175326332513e-05, 'epoch': 1.92}\n",
      "{'loss': 1.0564, 'grad_norm': 66.87300872802734, 'learning_rate': 1.30216058054557e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12843f695ca84e73866533b8d520ff03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.5421080984018675, 'eval_f1': 0.5427438398167861, 'eval_loss': 0.9257205128669739, 'eval_runtime': 129.1864, 'eval_samples_per_second': 43.108, 'eval_steps_per_second': 14.375, 'epoch': 2.0}\n",
      "{'loss': 1.03, 'grad_norm': 6.124541759490967, 'learning_rate': 1.3293036284578884e-05, 'epoch': 2.01}\n",
      "{'loss': 0.9802, 'grad_norm': 60.2114372253418, 'learning_rate': 1.3563923902743822e-05, 'epoch': 2.05}\n",
      "{'loss': 0.9531, 'grad_norm': 64.00323486328125, 'learning_rate': 1.3835354381867009e-05, 'epoch': 2.09}\n",
      "{'loss': 0.9351, 'grad_norm': 37.82403564453125, 'learning_rate': 1.4106242000031947e-05, 'epoch': 2.13}\n",
      "{'loss': 0.9746, 'grad_norm': 16.772634506225586, 'learning_rate': 1.4377672479155133e-05, 'epoch': 2.17}\n",
      "{'loss': 0.9465, 'grad_norm': 24.6521053314209, 'learning_rate': 1.4649102958278318e-05, 'epoch': 2.21}\n",
      "{'loss': 0.9418, 'grad_norm': 69.53672790527344, 'learning_rate': 1.4920533437401504e-05, 'epoch': 2.25}\n",
      "{'loss': 0.9725, 'grad_norm': 16.6578426361084, 'learning_rate': 1.519196391652469e-05, 'epoch': 2.29}\n",
      "{'loss': 0.9621, 'grad_norm': 29.099245071411133, 'learning_rate': 1.5463394395647875e-05, 'epoch': 2.33}\n",
      "{'loss': 0.9347, 'grad_norm': 7.633969306945801, 'learning_rate': 1.5734282013812814e-05, 'epoch': 2.38}\n",
      "{'loss': 0.9557, 'grad_norm': 40.904579162597656, 'learning_rate': 1.6005712492936e-05, 'epoch': 2.42}\n",
      "{'loss': 0.9614, 'grad_norm': 21.16887664794922, 'learning_rate': 1.6277142972059183e-05, 'epoch': 2.46}\n",
      "{'loss': 0.9548, 'grad_norm': 52.81398391723633, 'learning_rate': 1.654857345118237e-05, 'epoch': 2.5}\n",
      "{'loss': 0.965, 'grad_norm': 26.441783905029297, 'learning_rate': 1.6820003930305556e-05, 'epoch': 2.54}\n",
      "{'loss': 0.9643, 'grad_norm': 9.248602867126465, 'learning_rate': 1.7091434409428744e-05, 'epoch': 2.58}\n",
      "{'loss': 0.9454, 'grad_norm': 64.44178771972656, 'learning_rate': 1.7362864888551925e-05, 'epoch': 2.62}\n",
      "{'loss': 0.9728, 'grad_norm': 4.7457499504089355, 'learning_rate': 1.7634295367675113e-05, 'epoch': 2.66}\n",
      "{'loss': 0.9763, 'grad_norm': 13.496034622192383, 'learning_rate': 1.7905725846798298e-05, 'epoch': 2.7}\n",
      "{'loss': 0.973, 'grad_norm': 21.526384353637695, 'learning_rate': 1.8176613464963236e-05, 'epoch': 2.74}\n",
      "{'loss': 0.9523, 'grad_norm': 20.811094284057617, 'learning_rate': 1.8448043944086424e-05, 'epoch': 2.78}\n",
      "{'loss': 0.917, 'grad_norm': 15.826096534729004, 'learning_rate': 1.8719474423209605e-05, 'epoch': 2.83}\n",
      "{'loss': 0.9315, 'grad_norm': 83.42687225341797, 'learning_rate': 1.8990904902332793e-05, 'epoch': 2.87}\n",
      "{'loss': 0.9657, 'grad_norm': 20.86747169494629, 'learning_rate': 1.9262335381455978e-05, 'epoch': 2.91}\n",
      "{'loss': 0.9136, 'grad_norm': 52.625831604003906, 'learning_rate': 1.953322299962092e-05, 'epoch': 2.95}\n",
      "{'loss': 0.9279, 'grad_norm': 36.625892639160156, 'learning_rate': 1.9804653478744104e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4601e3caa0b04dae8e7775270bd0eb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.6186029807864967, 'eval_f1': 0.6182180568613557, 'eval_loss': 0.9976822137832642, 'eval_runtime': 129.1709, 'eval_samples_per_second': 43.113, 'eval_steps_per_second': 14.376, 'epoch': 3.0}\n",
      "{'loss': 0.8005, 'grad_norm': 18.805315017700195, 'learning_rate': 2.007554109690904e-05, 'epoch': 3.03}\n",
      "{'loss': 0.7618, 'grad_norm': 1.7467933893203735, 'learning_rate': 2.0346971576032227e-05, 'epoch': 3.07}\n",
      "{'loss': 0.8173, 'grad_norm': 10.063373565673828, 'learning_rate': 2.0618402055155412e-05, 'epoch': 3.11}\n",
      "{'loss': 0.8088, 'grad_norm': 4.948492050170898, 'learning_rate': 2.08898325342786e-05, 'epoch': 3.15}\n",
      "{'loss': 0.7888, 'grad_norm': 45.62972640991211, 'learning_rate': 2.1161263013401785e-05, 'epoch': 3.19}\n",
      "{'loss': 0.8674, 'grad_norm': 31.724933624267578, 'learning_rate': 2.143269349252497e-05, 'epoch': 3.24}\n",
      "{'loss': 0.7657, 'grad_norm': 33.06605911254883, 'learning_rate': 2.1704123971648154e-05, 'epoch': 3.28}\n",
      "{'loss': 0.8493, 'grad_norm': 16.989675521850586, 'learning_rate': 2.197555445077134e-05, 'epoch': 3.32}\n",
      "{'loss': 0.8402, 'grad_norm': 35.69833755493164, 'learning_rate': 2.2246984929894527e-05, 'epoch': 3.36}\n",
      "{'loss': 0.8749, 'grad_norm': 28.90913963317871, 'learning_rate': 2.251841540901771e-05, 'epoch': 3.4}\n",
      "{'loss': 0.8406, 'grad_norm': 15.977958679199219, 'learning_rate': 2.2789845888140896e-05, 'epoch': 3.44}\n",
      "{'loss': 0.8446, 'grad_norm': 1.3704063892364502, 'learning_rate': 2.3060733506305834e-05, 'epoch': 3.48}\n",
      "{'loss': 0.894, 'grad_norm': 41.822669982910156, 'learning_rate': 2.3332163985429022e-05, 'epoch': 3.52}\n",
      "{'loss': 0.8895, 'grad_norm': 11.897102355957031, 'learning_rate': 2.3603594464552207e-05, 'epoch': 3.56}\n",
      "{'loss': 0.8345, 'grad_norm': 2.144068479537964, 'learning_rate': 2.387502494367539e-05, 'epoch': 3.6}\n",
      "{'loss': 0.843, 'grad_norm': 13.907278060913086, 'learning_rate': 2.414645542279858e-05, 'epoch': 3.64}\n",
      "{'loss': 0.9042, 'grad_norm': 20.226835250854492, 'learning_rate': 2.441788590192176e-05, 'epoch': 3.69}\n",
      "{'loss': 0.8458, 'grad_norm': 11.757200241088867, 'learning_rate': 2.4688773520086703e-05, 'epoch': 3.73}\n",
      "{'loss': 0.8463, 'grad_norm': 45.452789306640625, 'learning_rate': 2.4960203999209887e-05, 'epoch': 3.77}\n",
      "{'loss': 0.8126, 'grad_norm': 14.714232444763184, 'learning_rate': 2.5231634478333075e-05, 'epoch': 3.81}\n",
      "{'loss': 0.8503, 'grad_norm': 22.2526798248291, 'learning_rate': 2.550306495745626e-05, 'epoch': 3.85}\n",
      "{'loss': 0.8785, 'grad_norm': 14.840360641479492, 'learning_rate': 2.5773952575621195e-05, 'epoch': 3.89}\n",
      "{'loss': 0.8253, 'grad_norm': 46.12831497192383, 'learning_rate': 2.6045383054744383e-05, 'epoch': 3.93}\n",
      "{'loss': 0.8493, 'grad_norm': 12.899779319763184, 'learning_rate': 2.6316813533867568e-05, 'epoch': 3.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6497e21cbe9d41a89e7fda2b40d68110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.6415873585922068, 'eval_f1': 0.6415504437113901, 'eval_loss': 1.0187714099884033, 'eval_runtime': 130.4745, 'eval_samples_per_second': 42.683, 'eval_steps_per_second': 14.233, 'epoch': 4.0}\n",
      "{'loss': 0.7835, 'grad_norm': 21.102596282958984, 'learning_rate': 2.6588244012990756e-05, 'epoch': 4.01}\n",
      "{'loss': 0.6664, 'grad_norm': 5.044328212738037, 'learning_rate': 2.685967449211394e-05, 'epoch': 4.05}\n",
      "{'loss': 0.6521, 'grad_norm': 16.94122314453125, 'learning_rate': 2.7131104971237125e-05, 'epoch': 4.1}\n",
      "{'loss': 0.7038, 'grad_norm': 37.15906524658203, 'learning_rate': 2.740253545036031e-05, 'epoch': 4.14}\n",
      "{'loss': 0.75, 'grad_norm': 18.979867935180664, 'learning_rate': 2.7673423068525248e-05, 'epoch': 4.18}\n",
      "{'loss': 0.7511, 'grad_norm': 28.13322639465332, 'learning_rate': 2.794431068669019e-05, 'epoch': 4.22}\n",
      "{'loss': 0.7576, 'grad_norm': 11.955854415893555, 'learning_rate': 2.8215741165813374e-05, 'epoch': 4.26}\n",
      "{'loss': 0.7405, 'grad_norm': 9.219260215759277, 'learning_rate': 2.848717164493656e-05, 'epoch': 4.3}\n",
      "{'loss': 0.763, 'grad_norm': 27.077842712402344, 'learning_rate': 2.8758602124059744e-05, 'epoch': 4.34}\n",
      "{'loss': 0.803, 'grad_norm': 30.15535545349121, 'learning_rate': 2.903003260318293e-05, 'epoch': 4.38}\n",
      "{'loss': 0.7422, 'grad_norm': 67.7715835571289, 'learning_rate': 2.9301463082306116e-05, 'epoch': 4.42}\n",
      "{'loss': 0.7878, 'grad_norm': 12.841975212097168, 'learning_rate': 2.95728935614293e-05, 'epoch': 4.46}\n",
      "{'loss': 0.7561, 'grad_norm': 55.045257568359375, 'learning_rate': 2.9844324040552486e-05, 'epoch': 4.5}\n",
      "{'loss': 0.7522, 'grad_norm': 19.242769241333008, 'learning_rate': 3.011575451967567e-05, 'epoch': 4.55}\n",
      "{'loss': 0.7845, 'grad_norm': 18.728805541992188, 'learning_rate': 3.0387184998798858e-05, 'epoch': 4.59}\n",
      "{'loss': 0.8138, 'grad_norm': 23.57891273498535, 'learning_rate': 3.065861547792204e-05, 'epoch': 4.63}\n",
      "{'loss': 0.791, 'grad_norm': 37.53937911987305, 'learning_rate': 3.093004595704523e-05, 'epoch': 4.67}\n",
      "{'loss': 0.8087, 'grad_norm': 10.262370109558105, 'learning_rate': 3.120147643616841e-05, 'epoch': 4.71}\n",
      "{'loss': 0.8247, 'grad_norm': 20.24808120727539, 'learning_rate': 3.14729069152916e-05, 'epoch': 4.75}\n",
      "{'loss': 0.7917, 'grad_norm': 7.71514892578125, 'learning_rate': 3.174433739441478e-05, 'epoch': 4.79}\n",
      "{'loss': 0.8018, 'grad_norm': 9.705709457397461, 'learning_rate': 3.2015767873537966e-05, 'epoch': 4.83}\n",
      "{'loss': 0.7974, 'grad_norm': 3.0646936893463135, 'learning_rate': 3.228665549170291e-05, 'epoch': 4.87}\n",
      "{'loss': 0.8562, 'grad_norm': 1.8996127843856812, 'learning_rate': 3.2558085970826096e-05, 'epoch': 4.91}\n",
      "{'loss': 0.8045, 'grad_norm': 29.36471939086914, 'learning_rate': 3.282951644994928e-05, 'epoch': 4.95}\n",
      "{'loss': 0.8255, 'grad_norm': 37.36577606201172, 'learning_rate': 3.3100946929072465e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aae44deb45840f98d693ae70bb3c3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.6437421440114922, 'eval_f1': 0.643986597412205, 'eval_loss': 1.344173789024353, 'eval_runtime': 130.3053, 'eval_samples_per_second': 42.738, 'eval_steps_per_second': 14.251, 'epoch': 5.0}\n",
      "{'loss': 0.6788, 'grad_norm': 26.029659271240234, 'learning_rate': 3.337237740819565e-05, 'epoch': 5.04}\n",
      "{'loss': 0.6854, 'grad_norm': 0.8334842324256897, 'learning_rate': 3.364326502636059e-05, 'epoch': 5.08}\n",
      "{'loss': 0.6623, 'grad_norm': 29.628421783447266, 'learning_rate': 3.391469550548377e-05, 'epoch': 5.12}\n",
      "{'loss': 0.6937, 'grad_norm': 42.893489837646484, 'learning_rate': 3.4186125984606964e-05, 'epoch': 5.16}\n",
      "{'loss': 0.6594, 'grad_norm': 14.304396629333496, 'learning_rate': 3.445755646373015e-05, 'epoch': 5.2}\n",
      "{'loss': 0.6919, 'grad_norm': 1.6768128871917725, 'learning_rate': 3.472898694285333e-05, 'epoch': 5.24}\n",
      "{'loss': 0.759, 'grad_norm': 55.0181884765625, 'learning_rate': 3.499987456101827e-05, 'epoch': 5.28}\n",
      "{'loss': 0.6734, 'grad_norm': 0.09906376153230667, 'learning_rate': 3.5271305040141456e-05, 'epoch': 5.32}\n",
      "{'loss': 0.7168, 'grad_norm': 3.3665852546691895, 'learning_rate': 3.554273551926464e-05, 'epoch': 5.36}\n",
      "{'loss': 0.7606, 'grad_norm': 17.88541030883789, 'learning_rate': 3.5814165998387826e-05, 'epoch': 5.41}\n",
      "{'loss': 0.7222, 'grad_norm': 34.41759490966797, 'learning_rate': 3.608559647751102e-05, 'epoch': 5.45}\n",
      "{'loss': 0.7257, 'grad_norm': 0.46199601888656616, 'learning_rate': 3.63570269566342e-05, 'epoch': 5.49}\n",
      "{'loss': 0.7517, 'grad_norm': 60.869110107421875, 'learning_rate': 3.662845743575738e-05, 'epoch': 5.53}\n",
      "{'loss': 0.6933, 'grad_norm': 26.180139541625977, 'learning_rate': 3.689988791488057e-05, 'epoch': 5.57}\n",
      "{'loss': 0.7941, 'grad_norm': 124.86273956298828, 'learning_rate': 3.717023267208726e-05, 'epoch': 5.61}\n",
      "{'loss': 0.7337, 'grad_norm': 20.95762825012207, 'learning_rate': 3.7441120290252195e-05, 'epoch': 5.65}\n",
      "{'loss': 0.7363, 'grad_norm': 5.351559638977051, 'learning_rate': 3.7712550769375386e-05, 'epoch': 5.69}\n",
      "{'loss': 0.7832, 'grad_norm': 12.044846534729004, 'learning_rate': 3.798398124849857e-05, 'epoch': 5.73}\n",
      "{'loss': 0.7552, 'grad_norm': 9.128318786621094, 'learning_rate': 3.825541172762176e-05, 'epoch': 5.77}\n",
      "{'loss': 0.7966, 'grad_norm': 12.191381454467773, 'learning_rate': 3.852684220674494e-05, 'epoch': 5.81}\n",
      "{'loss': 0.7651, 'grad_norm': 14.79427433013916, 'learning_rate': 3.879772982490988e-05, 'epoch': 5.86}\n",
      "{'loss': 0.8195, 'grad_norm': 25.712448120117188, 'learning_rate': 3.906916030403307e-05, 'epoch': 5.9}\n",
      "{'loss': 0.8213, 'grad_norm': 5.661149024963379, 'learning_rate': 3.934059078315625e-05, 'epoch': 5.94}\n",
      "{'loss': 0.7788, 'grad_norm': 14.934768676757812, 'learning_rate': 3.961202126227944e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7359ffa9522f4104ac55fd97fba01d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.6502065002693482, 'eval_f1': 0.6480668146829563, 'eval_loss': 1.1717666387557983, 'eval_runtime': 130.254, 'eval_samples_per_second': 42.755, 'eval_steps_per_second': 14.257, 'epoch': 6.0}\n",
      "{'loss': 0.7332, 'grad_norm': 38.68946838378906, 'learning_rate': 3.9883451741402624e-05, 'epoch': 6.02}\n",
      "{'loss': 0.6181, 'grad_norm': 1.2194770574569702, 'learning_rate': 4.0154882220525815e-05, 'epoch': 6.06}\n",
      "{'loss': 0.6082, 'grad_norm': 34.59031295776367, 'learning_rate': 4.042631269964899e-05, 'epoch': 6.1}\n",
      "{'loss': 0.7004, 'grad_norm': 6.616634845733643, 'learning_rate': 4.069720031781393e-05, 'epoch': 6.14}\n",
      "{'loss': 0.6777, 'grad_norm': 0.04622616246342659, 'learning_rate': 4.096863079693712e-05, 'epoch': 6.18}\n",
      "{'loss': 0.6969, 'grad_norm': 103.87966918945312, 'learning_rate': 4.12400612760603e-05, 'epoch': 6.22}\n",
      "{'loss': 0.7291, 'grad_norm': 16.712339401245117, 'learning_rate': 4.151149175518349e-05, 'epoch': 6.27}\n",
      "{'loss': 0.7262, 'grad_norm': 35.68686294555664, 'learning_rate': 4.178292223430668e-05, 'epoch': 6.31}\n",
      "{'loss': 0.7642, 'grad_norm': 24.409412384033203, 'learning_rate': 4.205380985247161e-05, 'epoch': 6.35}\n",
      "{'loss': 0.7333, 'grad_norm': 7.341552257537842, 'learning_rate': 4.23252403315948e-05, 'epoch': 6.39}\n",
      "{'loss': 0.8026, 'grad_norm': 13.403573036193848, 'learning_rate': 4.259612794975974e-05, 'epoch': 6.43}\n",
      "{'loss': 0.697, 'grad_norm': 6.32455587387085, 'learning_rate': 4.286755842888293e-05, 'epoch': 6.47}\n",
      "{'loss': 0.7866, 'grad_norm': 0.24279490113258362, 'learning_rate': 4.313898890800611e-05, 'epoch': 6.51}\n",
      "{'loss': 0.8201, 'grad_norm': 29.289897918701172, 'learning_rate': 4.341041938712929e-05, 'epoch': 6.55}\n",
      "{'loss': 0.7664, 'grad_norm': 7.577607154846191, 'learning_rate': 4.3681849866252484e-05, 'epoch': 6.59}\n",
      "{'loss': 0.7804, 'grad_norm': 62.514766693115234, 'learning_rate': 4.3952737484417415e-05, 'epoch': 6.63}\n",
      "{'loss': 0.8265, 'grad_norm': 16.73362922668457, 'learning_rate': 4.422416796354061e-05, 'epoch': 6.67}\n",
      "{'loss': 0.7176, 'grad_norm': 0.13164299726486206, 'learning_rate': 4.449559844266379e-05, 'epoch': 6.72}\n",
      "{'loss': 0.8936, 'grad_norm': 0.9042079448699951, 'learning_rate': 4.4767028921786976e-05, 'epoch': 6.76}\n",
      "{'loss': 0.9879, 'grad_norm': 0.44001927971839905, 'learning_rate': 4.503845940091016e-05, 'epoch': 6.8}\n",
      "{'loss': 0.8422, 'grad_norm': 10.32852554321289, 'learning_rate': 4.5309889880033345e-05, 'epoch': 6.84}\n",
      "{'loss': 0.8249, 'grad_norm': 0.5242711305618286, 'learning_rate': 4.558132035915654e-05, 'epoch': 6.88}\n",
      "{'loss': 0.8155, 'grad_norm': 161.19961547851562, 'learning_rate': 4.5852750838279715e-05, 'epoch': 6.92}\n",
      "{'loss': 0.8116, 'grad_norm': 467.6871032714844, 'learning_rate': 4.612363845644465e-05, 'epoch': 6.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4035f78cf3814a0594484d1e3ee2a385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.6414077931405997, 'eval_f1': 0.64276980382379, 'eval_loss': 1.5463054180145264, 'eval_runtime': 128.7807, 'eval_samples_per_second': 43.244, 'eval_steps_per_second': 14.42, 'epoch': 7.0}\n",
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "{'train_runtime': 20758.428, 'train_samples_per_second': 52.938, 'train_steps_per_second': 17.646, 'train_loss': 0.9223125685833206, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9058ecfaf36346c380bb54f17a0a8cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 11:10:20,203] Trial 4 finished with value: 0.6502065002693482 and parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.2500228054734358, 'learning_rate': 6.331007353356651e-05, 'batch_size': 3, 'warmup_ratio': 0.31837920111611373, 'weight_decay': 0.09971031186766507, 'adam_beta1': 0.8682929292594384, 'adam_beta2': 0.9909672212836867, 'adam_epsilon': 5.424397228138408e-07, 'lr_scheduler_type': 'linear'}. Best is trial 4 with value: 0.6502065002693482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Current Trial 5 parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.43619344239874647, 'learning_rate': 4.744804985319591e-07, 'batch_size': 3, 'warmup_ratio': 0.6610094216704753, 'weight_decay': 0.214015165889555, 'adam_beta1': 0.8312852854211105, 'adam_beta2': 0.996036397101193, 'adam_epsilon': 5.420035889344036e-08, 'lr_scheduler_type': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForMultipleChoice were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18c453a59304d2c89b56e406e2eb894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6085, 'grad_norm': 1.0757840871810913, 'learning_rate': 9.798133601482668e-10, 'epoch': 0.04}\n",
      "{'loss': 1.6087, 'grad_norm': 1.0348371267318726, 'learning_rate': 1.957667093576237e-09, 'epoch': 0.08}\n",
      "{'loss': 1.609, 'grad_norm': 0.9857816696166992, 'learning_rate': 2.9355208270042074e-09, 'epoch': 0.12}\n",
      "{'loss': 1.609, 'grad_norm': 0.9480171799659729, 'learning_rate': 3.915334187152474e-09, 'epoch': 0.16}\n",
      "{'loss': 1.6091, 'grad_norm': 0.9768244624137878, 'learning_rate': 4.895147547300741e-09, 'epoch': 0.2}\n",
      "{'loss': 1.6093, 'grad_norm': 0.982633650302887, 'learning_rate': 5.8749609074490075e-09, 'epoch': 0.25}\n",
      "{'loss': 1.6088, 'grad_norm': 1.8424819707870483, 'learning_rate': 6.8528146408769786e-09, 'epoch': 0.29}\n",
      "{'loss': 1.609, 'grad_norm': 0.988273024559021, 'learning_rate': 7.832628001025244e-09, 'epoch': 0.33}\n",
      "{'loss': 1.6085, 'grad_norm': 1.1059460639953613, 'learning_rate': 8.81244136117351e-09, 'epoch': 0.37}\n",
      "{'loss': 1.6093, 'grad_norm': 1.0883785486221313, 'learning_rate': 9.792254721321779e-09, 'epoch': 0.41}\n",
      "{'loss': 1.6091, 'grad_norm': 1.1354783773422241, 'learning_rate': 1.077010845474975e-08, 'epoch': 0.45}\n",
      "{'loss': 1.6095, 'grad_norm': 1.0810142755508423, 'learning_rate': 1.1749921814898015e-08, 'epoch': 0.49}\n",
      "{'loss': 1.6086, 'grad_norm': 1.059558629989624, 'learning_rate': 1.2729735175046282e-08, 'epoch': 0.53}\n",
      "{'loss': 1.6095, 'grad_norm': 1.0277293920516968, 'learning_rate': 1.370954853519455e-08, 'epoch': 0.57}\n",
      "{'loss': 1.6082, 'grad_norm': 1.0557674169540405, 'learning_rate': 1.4689361895342816e-08, 'epoch': 0.61}\n",
      "{'loss': 1.6086, 'grad_norm': 1.0446022748947144, 'learning_rate': 1.5667215628770787e-08, 'epoch': 0.66}\n",
      "{'loss': 1.6082, 'grad_norm': 1.0586448907852173, 'learning_rate': 1.664702898891905e-08, 'epoch': 0.7}\n",
      "{'loss': 1.6079, 'grad_norm': 1.148160457611084, 'learning_rate': 1.762684234906732e-08, 'epoch': 0.74}\n",
      "{'loss': 1.608, 'grad_norm': 1.1914886236190796, 'learning_rate': 1.8606655709215586e-08, 'epoch': 0.78}\n",
      "{'loss': 1.6092, 'grad_norm': 1.0065940618515015, 'learning_rate': 1.9584509442643558e-08, 'epoch': 0.82}\n",
      "{'loss': 1.6086, 'grad_norm': 1.2320585250854492, 'learning_rate': 2.0564322802791822e-08, 'epoch': 0.86}\n",
      "{'loss': 1.6081, 'grad_norm': 1.0341814756393433, 'learning_rate': 2.154413616294009e-08, 'epoch': 0.9}\n",
      "{'loss': 1.6085, 'grad_norm': 1.0837699174880981, 'learning_rate': 2.252198989636806e-08, 'epoch': 0.94}\n",
      "{'loss': 1.6084, 'grad_norm': 1.0983372926712036, 'learning_rate': 2.350180325651633e-08, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64d938ac753494fb2b66562a94a4673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.31836954569940745, 'eval_f1': 0.32442948394051324, 'eval_loss': 1.607865333557129, 'eval_runtime': 130.1834, 'eval_samples_per_second': 42.778, 'eval_steps_per_second': 14.264, 'epoch': 1.0}\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n",
      "{'train_runtime': 2976.1961, 'train_samples_per_second': 369.23, 'train_steps_per_second': 123.077, 'train_loss': 1.6087190195344492, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b080a2d16a4c40b8de1e86c19799ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1857 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training: No improvement in eval_accuracy for 1 epochs\n",
      "Stopping training: eval_accuracy below manual min_acc of 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 12:02:06,610] Trial 5 finished with value: 0.31836954569940745 and parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.43619344239874647, 'learning_rate': 4.744804985319591e-07, 'batch_size': 3, 'warmup_ratio': 0.6610094216704753, 'weight_decay': 0.214015165889555, 'adam_beta1': 0.8312852854211105, 'adam_beta2': 0.996036397101193, 'adam_epsilon': 5.420035889344036e-08, 'lr_scheduler_type': 'linear'}. Best is trial 4 with value: 0.6502065002693482.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Trial 6 parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.23732993865505386, 'learning_rate': 1.1685926112932391e-07, 'batch_size': 4, 'warmup_ratio': 0.8400211050841219, 'weight_decay': 0.05868908832126296, 'adam_beta1': 0.8519566435750197, 'adam_beta2': 0.9913554074386653, 'adam_epsilon': 7.201851832756769e-07, 'lr_scheduler_type': 'cosine_with_restarts'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForMultipleChoice were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937d8e6ef254426490c63fc5260ce914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6096, 'grad_norm': 0.892684817314148, 'learning_rate': 2.5165542741075785e-10, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-22 12:04:46,078] Trial 6 failed with parameters: {'model_name': 'sentence-transformers/all-mpnet-base-v2', 'dropout_rate': 0.23732993865505386, 'learning_rate': 1.1685926112932391e-07, 'batch_size': 4, 'warmup_ratio': 0.8400211050841219, 'weight_decay': 0.05868908832126296, 'adam_beta1': 0.8519566435750197, 'adam_beta2': 0.9913554074386653, 'adam_epsilon': 7.201851832756769e-07, 'lr_scheduler_type': 'cosine_with_restarts'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\OEM\\AppData\\Local\\Temp\\ipykernel_29776\\2979044354.py\", line 60, in objective\n",
      "    trainer.train()\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py\", line 1938, in train\n",
      "    return inner_training_loop(\n",
      "  File \"c:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py\", line 2284, in _inner_training_loop\n",
      "    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-22 12:04:46,080] Trial 6 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m study\u001b[38;5;241m.\u001b[39menqueue_trial({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m: pretrained_model_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.5807103066634623e-05\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarmup_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.5994150649377659\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.12506835879573128\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam_beta1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.8136227307274486\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam_beta2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.9924116710027883\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam_epsilon\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.9858068243318367e-07\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_scheduler_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine_with_restarts\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m----> 5\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[24], line 60\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     49\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     50\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_init(model_name, dropout_rate),\n\u001b[0;32m     51\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[AdvancedEarlyStoppingCallback(metric_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     63\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OEM\\anaconda3\\envs\\compsci714win\\lib\\site-packages\\transformers\\trainer.py:2284\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m   2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m-> 2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2285\u001b[0m ):\n\u001b[0;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   2288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a study object and optimize the objective for pretrained_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "global_run_name=\"Optuna-2\"\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.enqueue_trial({'model_name': pretrained_model_name, 'learning_rate': 1.5807103066634623e-05, 'batch_size': 4, 'warmup_ratio': 0.5994150649377659, 'weight_decay': 0.12506835879573128, 'adam_beta1': 0.8136227307274486, 'adam_beta2': 0.9924116710027883, 'adam_epsilon': 1.9858068243318367e-07, 'lr_scheduler_type': 'cosine_with_restarts'})\n",
    "study.optimize(objective, n_trials=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0629740",
   "metadata": {},
   "source": [
    "## 4.4 Optuna Hyperparameters Tuning 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b567c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98fb9f12-d022-4590-af99-611fc317aeaf",
   "metadata": {},
   "source": [
    "# End of NoteBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a6a10-fee5-4be2-b061-29591435f60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compsci714win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
